{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn as nn\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all the data from the CSV file \n",
    "PT_DATA_PATH = \"../../../Dataset/Botnet_Detection/PT_838_Security Camera\"\n",
    "PT2_DATA_PATH = \"../../../Dataset/Botnet_Detection/PT737E_Security Camera\"\n",
    "XC_DATA_PATH = \"../../../Dataset/Botnet_Detection/XCS7_1002_WHT_Security_Camera\"\n",
    "XC2_DATA_PATH = \"../../../Dataset/Botnet_Detection/XCS7_1003_WHT_Security_Camera\"\n",
    "df_pt_1 = pd.read_csv(PT_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_pt_2 = pd.read_csv(PT2_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_xc_1 =  pd.read_csv(XC_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_xc_2 =  pd.read_csv(XC2_DATA_PATH+\"/benign_traffic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt1 = df_pt_1.assign(label = 'pt1')\n",
    "df_pt2 = df_pt_2.assign(label = 'pt2')\n",
    "df_xc1 = df_xc_1.assign(label = 'xc1')\n",
    "df_xc2 = df_xc_2.assign(label = 'xc2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_pt1\n",
    "#df_all = df_all.append(df_pt2, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = shuffler(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for OMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 116)\n"
     ]
    }
   ],
   "source": [
    "#Sample some instances from the dataset \n",
    "test_set = df_pt1.sample(frac=0.001, random_state=1)\n",
    "test_set = test_set.append(df_xc1.sample(frac=0.001, random_state=1))\n",
    "test_set = shuffler(test_set)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pd.DataFrame(df_all.iloc[:, 0:115])\n",
    "train_y = pd.DataFrame(df_all.iloc[:, 115])\n",
    "test_x = pd.DataFrame(test_set.iloc[:, 0:115])\n",
    "test_y = pd.DataFrame(test_set.iloc[:, 115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = normalize(train_x)\n",
    "test_x = normalize(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['pt1'], dtype=object)]\n",
      "[array(['pt1', 'xc1'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "train_y = label_encoder(train_y)\n",
    "test_y = label_encoder(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.FloatTensor(train_x.values.astype(np.float32))\n",
    "test_x = torch.tensor(test_x.values.astype(np.float32))\n",
    "train_y = torch.tensor(train_y.astype(np.float32))\n",
    "test_y = torch.tensor(test_y.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Divide dataframe into x and y\n",
    "df_x = pd.DataFrame(df_all.iloc[:, 0:115])\n",
    "df_y = pd.DataFrame(df_all.iloc[:, 115])\n",
    "df_pt2_x = pd.DataFrame(df_pt2.iloc[:, 0:115])\n",
    "df_pt2_y = pd.DataFrame(df_pt2.iloc[:, 115])\n",
    "df_xc_x = pd.DataFrame(df_xc1.iloc[:, 0:115])\n",
    "df_xc_y = pd.DataFrame(df_xc1.iloc[:, 115])\n",
    "df_xc2_x = pd.DataFrame(df_xc2.iloc[:, 0:115])\n",
    "df_xc2_y = pd.DataFrame(df_xc2.iloc[:, 115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the x dataframe\n",
    "df_x = normalize(df_x)\n",
    "df_pt2 = normalize(df_pt2_x)\n",
    "df_xc = normalize(df_xc_x)\n",
    "df_xc2 = normalize(df_xc2_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot encoding labels and transform into array\n",
    "df_y = label_encoder(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide dataset into training set and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_x, df_y, test_size=0.40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_dim, h_dim, out_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(in_dim, h_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(h_dim)\n",
    "        self.linear2 = torch.nn.Linear(h_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = torch.FloatTensor(train_x.values.astype(np.float32))\n",
    "test_x = torch.tensor(test_x.values.astype(np.float32))\n",
    "train_y = torch.tensor(train_y.astype(np.float32))\n",
    "test_y = torch.tensor(test_y.astype(np.float32))\n",
    "xc_x = torch.tensor(df_xc.values.astype(np.float32))\n",
    "pt2_x = torch.tensor(df_pt2.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.mean(), test_x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 600\n",
    "input_dim = 115\n",
    "output_dim = 2 #Number of clasees\n",
    "h_dim = 100\n",
    "lr_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_dim, h_dim, output_dim)\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_test, y_bm = test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(epochs, model, train_data, labels, vali_data, target):\n",
    "    for e in range(int(epochs)):\n",
    "        y_pred = model(train_data)\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, labels)\n",
    "        if e % 100 == 99:\n",
    "            loss_f = float(loss)\n",
    "            print(e, \"Loss:\", loss_f)\n",
    "            total = n_test\n",
    "            correct = 0.0\n",
    "            outputs = model(vali_data)\n",
    "            _b, pred = torch.max(outputs, 1)\n",
    "            vb, label = torch.max(target, 1)\n",
    "            correct+= float((pred == label).sum())\n",
    "            accuracy = float(100*(correct/total))\n",
    "            print('Accuracy: {:.4f}'.format(accuracy))\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training(epochs, model, train_x, train_y, test_x, test_y) ## Train the initial model on Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxind(V, r):\n",
    "    res=[]\n",
    "    for row in V:\n",
    "        l2 = np.linalg.norm(row)\n",
    "        row = row.unsqueeze(1)\n",
    "        row = torch.transpose(row,0,1)       \n",
    "        row = row.squeeze(0)\n",
    "        r = r.squeeze(0)\n",
    "        inner = float(torch.dot(row, r))\n",
    "        s = float(inner/l2)\n",
    "        res.append(s)\n",
    "        res_tensor = torch.FloatTensor(res)\n",
    "    \n",
    "    _, i = torch.max(res_tensor, 0)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor([[1,2,3],[4,5,6],[7,8,9],[1,0,2],[2,0,0]])\n",
    "b = torch.FloatTensor([[1,0,1]])\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.cat([a,b], 0)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxind(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: The vector(row) picked from the matrix cannot be re-sized directly.\n",
    "## y is expected as 2D matrix\n",
    "def OMP(y, V, sl, ep):\n",
    "    c_encode = torch.zeros([1, len(V)], dtype=torch.float32)\n",
    "    s_index = []\n",
    "    r = y\n",
    "    k = 1\n",
    "    while (k <= sl) and (np.linalg.norm(r) >= ep):\n",
    "        i = int(maxind(V, r))\n",
    "        s_index.append(i)\n",
    "        temp = []\n",
    "        for sk in s_index:\n",
    "            temp_v = V[sk]\n",
    "            if len(temp)==0:\n",
    "                temp=temp_v\n",
    "                temp = temp.unsqueeze(0)\n",
    "            else:\n",
    "                temp_v = V[sk].unsqueeze(0)\n",
    "                temp = torch.cat((temp, temp_v),0)\n",
    "               \n",
    "        \n",
    "        s_matrix = temp\n",
    "        s_matrix = s_matrix.type(torch.FloatTensor)\n",
    "        s_i = torch.pinverse(s_matrix)\n",
    "        c = torch.mm(y, s_i)\n",
    "        r = y - torch.mm(c, s_matrix)\n",
    "        k = k+1\n",
    "    \n",
    "    print(s_index)\n",
    "    v=0\n",
    "    for sk in s_index:\n",
    "        c_encode[0][sk] = c[0][v]\n",
    "        v = v+1\n",
    "    return c_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMP(b, a, 20, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test_x[45][:].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = OMP(y, train_x[:300][:], 10, 0.001)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = y - torch.mm(c, train_x[:300][:])\n",
    "print(np.linalg.norm(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 135, 130, 3, 152]\n",
      "[135, 160, 160, 89, 4]\n",
      "[114, 154, 4, 167, 4]\n",
      "[114, 167, 4, 154, 154]\n",
      "[120, 54, 167, 156, 81]\n",
      "[46, 160, 167, 113, 33]\n",
      "[12, 54, 167, 156, 81]\n",
      "[46, 33, 167, 46, 128]\n",
      "[18, 81, 18, 113, 113]\n",
      "[81, 113, 51, 69, 170]\n",
      "[46, 33, 167, 113, 160]\n",
      "[151, 46, 113, 159, 113]\n",
      "[152, 135, 152, 152, 152]\n",
      "[46, 160, 113, 167, 160]\n",
      "[46, 33, 167, 113, 33]\n",
      "[99, 135, 167, 180, 180]\n",
      "[114, 99, 180, 4, 195]\n",
      "[46, 33, 167, 113, 33]\n",
      "[165, 33, 135, 33, 165]\n",
      "[81, 46, 4, 113, 180]\n",
      "[81, 113, 46, 159, 46]\n",
      "[46, 33, 167, 46, 128]\n",
      "[159, 167, 46, 180, 81]\n",
      "[51, 180, 170, 113, 74]\n",
      "[46, 113, 4, 81, 159]\n",
      "[24, 183, 190, 183, 183]\n",
      "[183, 160, 190, 61, 61]\n",
      "[140, 140, 135, 140, 140]\n",
      "[160, 190, 190, 190, 139]\n",
      "[167, 46, 167, 46, 9]\n",
      "[24, 183, 190, 183, 183]\n",
      "[51, 180, 113, 170, 74]\n",
      "[24, 183, 190, 109, 183]\n",
      "[154, 33, 135, 156, 46]\n",
      "[102, 135, 46, 99, 169]\n",
      "[140, 135, 180, 135, 135]\n",
      "[92, 46, 167, 180, 4]\n",
      "[151, 46, 113, 151, 113]\n",
      "[180, 180, 41, 135, 180]\n",
      "[114, 4, 180, 114, 180]\n",
      "[160, 183, 135, 113, 113]\n",
      "[46, 33, 167, 113, 33]\n",
      "[180, 81, 156, 116, 180]\n",
      "[114, 154, 4, 167, 114]\n",
      "[81, 113, 51, 69, 170]\n",
      "[70, 167, 180, 4, 81]\n",
      "[180, 135, 167, 81, 135]\n",
      "[9, 59, 198, 13, 73]\n",
      "[109, 183, 190, 113, 160]\n",
      "[46, 33, 113, 190, 167]\n",
      "[114, 154, 4, 99, 99]\n",
      "[180, 167, 4, 81, 4]\n",
      "[156, 180, 180, 180, 180]\n",
      "[194, 183, 160, 46, 109]\n",
      "[81, 113, 46, 159, 113]\n",
      "[140, 169, 140, 140, 128]\n",
      "[114, 167, 154, 167, 167]\n",
      "[151, 180, 169, 113, 159]\n",
      "[114, 167, 180, 4, 180]\n",
      "[46, 113, 81, 159, 46]\n",
      "[109, 183, 160, 113, 190]\n",
      "[180, 113, 151, 46, 113]\n",
      "[46, 128, 113, 33, 160]\n",
      "[180, 151, 4, 88, 102]\n",
      "[51, 180, 113, 170, 74]\n",
      "[51, 180, 170, 113, 159]\n",
      "[81, 113, 46, 4, 51]\n",
      "[167, 46, 135, 167, 167]\n",
      "[113, 51, 113, 113, 135]\n",
      "[137, 160, 61, 160, 160]\n",
      "[114, 167, 180, 4, 154]\n",
      "[54, 137, 4, 135, 4]\n",
      "[159, 90, 51, 180, 113]\n",
      "[18, 113, 81, 46, 113]\n",
      "[46, 33, 167, 113, 160]\n",
      "[81, 113, 159, 152, 18]\n",
      "[137, 190, 61, 160, 190]\n",
      "[81, 113, 170, 74, 113]\n",
      "[159, 167, 46, 180, 9]\n",
      "[159, 169, 51, 180, 180]\n",
      "[85, 140, 140, 85, 9]\n",
      "[114, 167, 180, 167, 167]\n",
      "[151, 180, 46, 156, 159]\n",
      "[180, 167, 81, 135, 114]\n",
      "[24, 183, 190, 61, 24]\n",
      "[160, 190, 190, 190, 59]\n",
      "[184, 85, 135, 37, 183]\n",
      "[81, 113, 46, 159, 46]\n",
      "[70, 167, 180, 4, 114]\n",
      "[160, 190, 137, 33, 61]\n",
      "[46, 33, 167, 113, 33]\n",
      "[46, 33, 167, 113, 33]\n",
      "[24, 183, 190, 61, 24]\n",
      "[154, 180, 135, 72, 4]\n",
      "[114, 4, 180, 195, 180]\n",
      "[4, 46, 167, 81, 180]\n",
      "[102, 191, 180, 51, 113]\n",
      "[4, 46, 167, 81, 180]\n",
      "[192, 167, 180, 4, 114]\n",
      "[42, 167, 180, 4, 114]\n",
      "[180, 33, 46, 135, 9]\n",
      "[70, 167, 180, 4, 81]\n",
      "[46, 33, 167, 113, 160]\n",
      "[33, 183, 61, 190, 137]\n",
      "[46, 33, 113, 167, 160]\n",
      "[46, 33, 113, 190, 46]\n",
      "[42, 167, 180, 4, 81]\n",
      "[81, 113, 148, 137, 46]\n",
      "[81, 113, 51, 69, 81]\n",
      "[81, 113, 51, 69, 180]\n",
      "[137, 160, 61, 160, 160]\n",
      "[165, 4, 61, 135, 152]\n",
      "[102, 176, 156, 113, 151]\n",
      "[81, 113, 170, 74, 18]\n",
      "[159, 167, 46, 156, 113]\n",
      "[46, 33, 167, 113, 160]\n",
      "[46, 180, 113, 81, 159]\n",
      "[109, 183, 160, 46, 190]\n",
      "[114, 4, 101, 180, 180]\n",
      "[114, 135, 154, 9, 4]\n",
      "[114, 154, 4, 114, 114]\n",
      "[137, 160, 61, 160, 160]\n",
      "[194, 183, 113, 190, 109]\n",
      "[88, 156, 113, 151, 46]\n",
      "[160, 190, 61, 160, 46]\n",
      "[46, 33, 167, 113, 160]\n",
      "[46, 33, 113, 167, 160]\n",
      "[81, 113, 46, 159, 81]\n",
      "[81, 113, 46, 159, 81]\n",
      "[99, 135, 46, 167, 180]\n",
      "[113, 180, 51, 113, 113]\n",
      "[46, 190, 167, 160, 160]\n",
      "[113, 180, 40, 51, 81]\n",
      "[3, 169, 135, 137, 113]\n",
      "[146, 140, 169, 169, 140]\n",
      "[81, 113, 170, 74, 113]\n",
      "[46, 33, 167, 113, 33]\n",
      "[51, 180, 113, 170, 74]\n",
      "[184, 183, 160, 184, 89]\n",
      "[160, 183, 46, 109, 113]\n",
      "[159, 33, 113, 169, 151]\n",
      "[114, 135, 154, 4, 9]\n",
      "[81, 113, 46, 159, 81]\n",
      "[184, 190, 183, 160, 61]\n",
      "[81, 113, 159, 33, 46]\n",
      "[114, 4, 51, 180, 119]\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "re = torch.zeros([len(test_x), 2], dtype=torch.float32)\n",
    "for ids, vector in enumerate(test_x):\n",
    "    v = vector.unsqueeze(0)\n",
    "    c = OMP(v, train_x[:200][:], 5, 0.001)\n",
    "    t = v - torch.mm(c, train_x[:200][:])\n",
    "    distance = np.linalg.norm(t)\n",
    "    if distance < 10000.0:\n",
    "        re[ids][0] = 1.0\n",
    "    else:\n",
    "        re[ids][1] = 1.0\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 51.3699\n"
     ]
    }
   ],
   "source": [
    "total = len(test_x)\n",
    "correct = 0.0\n",
    "_, pred = torch.max(re, 1)\n",
    "v, label = torch.max(test_y, 1)\n",
    "correct+= float((pred == label).sum())\n",
    "accuracy = float(100*(correct/total))\n",
    "print('Accuracy: {:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pysyft] *",
   "language": "python",
   "name": "conda-env-Pysyft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
