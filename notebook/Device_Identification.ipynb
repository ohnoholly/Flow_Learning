{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn as nn\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all the data from the CSV file \n",
    "PT_DATA_PATH = \"../../../Dataset/Botnet_Detection/PT_838_Security Camera\"\n",
    "PT2_DATA_PATH = \"../../../Dataset/Botnet_Detection/PT737E_Security Camera\"\n",
    "XC_DATA_PATH = \"../../../Dataset/Botnet_Detection/XCS7_1002_WHT_Security_Camera\"\n",
    "XC2_DATA_PATH = \"../../../Dataset/Botnet_Detection/XCS7_1003_WHT_Security_Camera\"\n",
    "df_pt_1 = pd.read_csv(PT_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_pt_2 = pd.read_csv(PT2_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_xc_1 =  pd.read_csv(XC_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_xc_2 =  pd.read_csv(XC2_DATA_PATH+\"/benign_traffic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt1 = df_pt_1.assign(label = 'pt1')\n",
    "df_pt2 = df_pt_2.assign(label = 'pt2')\n",
    "df_xc1 = df_xc_1.assign(label = 'xc1')\n",
    "df_xc2 = df_xc_2.assign(label = 'xc2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_pt1\n",
    "#df_all = df_all.append(df_pt2, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = shuffler(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for OMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 116)\n"
     ]
    }
   ],
   "source": [
    "#Sample some instances from the dataset \n",
    "test_set = df_pt1.sample(frac=0.001, random_state=1)\n",
    "test_set = test_set.append(df_xc1.sample(frac=0.001, random_state=1))\n",
    "#test_set = shuffler(test_set)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pd.DataFrame(df_all.iloc[:, 0:115])\n",
    "train_y = pd.DataFrame(df_all.iloc[:, 115])\n",
    "test_x = pd.DataFrame(test_set.iloc[:, 0:115])\n",
    "test_y = pd.DataFrame(test_set.iloc[:, 115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = normalize(train_x)\n",
    "test_x = normalize(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['pt1'], dtype=object)]\n",
      "[array(['pt1', 'xc1'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "train_y = label_encoder(train_y)\n",
    "test_y = label_encoder(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.FloatTensor(train_x.values.astype(np.float32))\n",
    "test_x = torch.tensor(test_x.values.astype(np.float32))\n",
    "train_y = torch.tensor(train_y.astype(np.float32))\n",
    "test_y = torch.tensor(test_y.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Divide dataframe into x and y\n",
    "df_x = pd.DataFrame(df_all.iloc[:, 0:115])\n",
    "df_y = pd.DataFrame(df_all.iloc[:, 115])\n",
    "df_pt2_x = pd.DataFrame(df_pt2.iloc[:, 0:115])\n",
    "df_pt2_y = pd.DataFrame(df_pt2.iloc[:, 115])\n",
    "df_xc_x = pd.DataFrame(df_xc1.iloc[:, 0:115])\n",
    "df_xc_y = pd.DataFrame(df_xc1.iloc[:, 115])\n",
    "df_xc2_x = pd.DataFrame(df_xc2.iloc[:, 0:115])\n",
    "df_xc2_y = pd.DataFrame(df_xc2.iloc[:, 115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the x dataframe\n",
    "df_x = normalize(df_x)\n",
    "df_pt2 = normalize(df_pt2_x)\n",
    "df_xc = normalize(df_xc_x)\n",
    "df_xc2 = normalize(df_xc2_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot encoding labels and transform into array\n",
    "df_y = label_encoder(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide dataset into training set and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_x, df_y, test_size=0.40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_dim, h_dim, out_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(in_dim, h_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(h_dim)\n",
    "        self.linear2 = torch.nn.Linear(h_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = torch.FloatTensor(train_x.values.astype(np.float32))\n",
    "test_x = torch.tensor(test_x.values.astype(np.float32))\n",
    "train_y = torch.tensor(train_y.astype(np.float32))\n",
    "test_y = torch.tensor(test_y.astype(np.float32))\n",
    "xc_x = torch.tensor(df_xc.values.astype(np.float32))\n",
    "pt2_x = torch.tensor(df_pt2.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.mean(), test_x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 600\n",
    "input_dim = 115\n",
    "output_dim = 2 #Number of clasees\n",
    "h_dim = 100\n",
    "lr_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_dim, h_dim, output_dim)\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_test, y_bm = test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(epochs, model, train_data, labels, vali_data, target):\n",
    "    for e in range(int(epochs)):\n",
    "        y_pred = model(train_data)\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, labels)\n",
    "        if e % 100 == 99:\n",
    "            loss_f = float(loss)\n",
    "            print(e, \"Loss:\", loss_f)\n",
    "            total = n_test\n",
    "            correct = 0.0\n",
    "            outputs = model(vali_data)\n",
    "            _b, pred = torch.max(outputs, 1)\n",
    "            vb, label = torch.max(target, 1)\n",
    "            correct+= float((pred == label).sum())\n",
    "            accuracy = float(100*(correct/total))\n",
    "            print('Accuracy: {:.4f}'.format(accuracy))\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training(epochs, model, train_x, train_y, test_x, test_y) ## Train the initial model on Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxind(V, r):\n",
    "    res=[]\n",
    "    for row in V:\n",
    "        l2 = np.linalg.norm(row)\n",
    "        row = row.unsqueeze(1)\n",
    "        row = torch.transpose(row,0,1)       \n",
    "        row = row.squeeze(0)\n",
    "        r = r.squeeze(0)\n",
    "        inner = float(torch.dot(row, r))\n",
    "        s = float(inner/l2)\n",
    "        res.append(s)\n",
    "        res_tensor = torch.FloatTensor(res)\n",
    "    \n",
    "    _, i = torch.max(res_tensor, 0)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor([[1,2,3],[4,5,6],[7,8,9],[1,0,2],[2,0,0]])\n",
    "b = torch.FloatTensor([[1,0,1]])\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.cat([a,b], 0)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxind(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: The vector(row) picked from the matrix cannot be re-sized directly.\n",
    "## y is expected as 2D matrix\n",
    "def OMP(y, V, sl, ep):\n",
    "    c_encode = torch.zeros([1, len(V)], dtype=torch.float32)\n",
    "    s_index = []\n",
    "    r = y\n",
    "    k = 1\n",
    "    while (k <= sl) and (np.linalg.norm(r) >= ep):\n",
    "        i = int(maxind(V, r))\n",
    "        s_index.append(i)\n",
    "        temp = []\n",
    "        for sk in s_index:\n",
    "            temp_v = V[sk]\n",
    "            if len(temp)==0:\n",
    "                temp=temp_v\n",
    "                temp = temp.unsqueeze(0)\n",
    "            else:\n",
    "                temp_v = V[sk].unsqueeze(0)\n",
    "                temp = torch.cat((temp, temp_v),0)\n",
    "               \n",
    "        \n",
    "        s_matrix = temp\n",
    "        s_matrix = s_matrix.type(torch.FloatTensor)\n",
    "        s_i = torch.pinverse(s_matrix)\n",
    "        c = torch.mm(y, s_i)\n",
    "        r = y - torch.mm(c, s_matrix)\n",
    "        k = k+1\n",
    "    \n",
    "    print(s_index)\n",
    "    v=0\n",
    "    for sk in s_index:\n",
    "        c_encode[0][sk] = c[0][v]\n",
    "        v = v+1\n",
    "    return c_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMP(b, a, 20, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test_x[5][:].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = OMP(y, train_x[:300][:], 10, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = y - torch.mm(c, train_x[:300][:])\n",
    "print(np.linalg.norm(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[380, 230, 63, 230, 125]\n",
      "id: {}, dist: {} 0 2547675.2\n",
      "[138, 230, 200, 230, 138]\n",
      "id: {}, dist: {} 1 1527792.8\n",
      "[457, 230, 23, 138, 274]\n",
      "id: {}, dist: {} 2 1.1372913\n",
      "[165, 230, 23, 274, 202]\n",
      "id: {}, dist: {} 3 1.133052\n",
      "[165, 23, 274, 230, 30]\n",
      "id: {}, dist: {} 4 1.1337138\n",
      "[498, 230, 202, 37, 230]\n",
      "id: {}, dist: {} 5 3059405.5\n",
      "[17, 230, 202, 435, 17]\n",
      "id: {}, dist: {} 6 80685.305\n",
      "[37, 230, 202, 323, 95]\n",
      "id: {}, dist: {} 7 1.192573\n",
      "[373, 230, 202, 23, 138]\n",
      "id: {}, dist: {} 8 1.1667582\n",
      "[63, 300, 230, 0, 380]\n",
      "id: {}, dist: {} 9 2.2596943\n",
      "[23, 230, 202, 23, 230]\n",
      "id: {}, dist: {} 10 671827.44\n",
      "[17, 429, 230, 451, 451]\n",
      "id: {}, dist: {} 11 149810.34\n",
      "[37, 219, 323, 244, 20]\n",
      "id: {}, dist: {} 12 1.3666815\n",
      "[88, 451, 499, 499, 499]\n",
      "id: {}, dist: {} 13 974858800000.0\n",
      "[359, 51, 230, 63, 380]\n",
      "id: {}, dist: {} 14 2.2903678\n",
      "[418, 230, 51, 94, 94]\n",
      "id: {}, dist: {} 15 1127079.0\n",
      "[165, 230, 23, 274, 30]\n",
      "id: {}, dist: {} 16 1.1201451\n",
      "[359, 380, 63, 230, 0]\n",
      "id: {}, dist: {} 17 2.4978416\n",
      "[489, 177, 51, 429, 230]\n",
      "id: {}, dist: {} 18 1.7550616\n",
      "[393, 230, 37, 202, 453]\n",
      "id: {}, dist: {} 19 1.2024168\n",
      "[159, 489, 162, 51, 230]\n",
      "id: {}, dist: {} 20 1.6696153\n",
      "[451, 51, 499, 499, 219]\n",
      "id: {}, dist: {} 21 20145156.0\n",
      "[18, 230, 23, 453, 45]\n",
      "id: {}, dist: {} 22 1.1441607\n",
      "[254, 230, 23, 138, 388]\n",
      "id: {}, dist: {} 23 1.14596\n",
      "[499, 451, 51, 499, 499]\n",
      "id: {}, dist: {} 24 30747784000000.0\n",
      "[207, 230, 63, 451, 94]\n",
      "id: {}, dist: {} 25 2.7305696\n",
      "[453, 177, 230, 230, 265]\n",
      "id: {}, dist: {} 26 5104370.0\n",
      "[99, 230, 453, 85, 37]\n",
      "id: {}, dist: {} 27 1.177381\n",
      "[294, 177, 429, 187, 435]\n",
      "id: {}, dist: {} 28 1.2245698\n",
      "[138, 230, 453, 202, 230]\n",
      "id: {}, dist: {} 29 2610433.2\n",
      "[435, 230, 202, 23, 138]\n",
      "id: {}, dist: {} 30 1.1667383\n",
      "[23, 230, 202, 23, 230]\n",
      "id: {}, dist: {} 31 563813.25\n",
      "[453, 95, 99, 230, 85]\n",
      "id: {}, dist: {} 32 1.1440575\n",
      "[359, 51, 230, 94, 63]\n",
      "id: {}, dist: {} 33 2.514249\n",
      "[294, 230, 429, 435, 191]\n",
      "id: {}, dist: {} 34 1.2665502\n",
      "[498, 230, 323, 202, 20]\n",
      "id: {}, dist: {} 35 1.2167764\n",
      "[165, 230, 23, 202, 138]\n",
      "id: {}, dist: {} 36 1.1314081\n",
      "[37, 230, 202, 122, 230]\n",
      "id: {}, dist: {} 37 381550.2\n",
      "[88, 451, 499, 88, 289]\n",
      "id: {}, dist: {} 38 6982519.0\n",
      "[177, 230, 439, 453, 362]\n",
      "id: {}, dist: {} 39 1.3317285\n",
      "[453, 230, 177, 177, 401]\n",
      "id: {}, dist: {} 40 115762.86\n",
      "[138, 23, 230, 202, 274]\n",
      "id: {}, dist: {} 41 1.1400006\n",
      "[386, 230, 203, 203, 265]\n",
      "id: {}, dist: {} 42 147793570.0\n",
      "[160, 230, 202, 23, 453]\n",
      "id: {}, dist: {} 43 1.1588436\n",
      "[50, 230, 453, 20, 37]\n",
      "id: {}, dist: {} 44 1.1681345\n",
      "[165, 230, 23, 202, 274]\n",
      "id: {}, dist: {} 45 1.1320503\n",
      "[177, 383, 230, 177, 401]\n",
      "id: {}, dist: {} 46 510102.22\n",
      "[38, 207, 453, 202, 343]\n",
      "id: {}, dist: {} 47 1.2924452\n",
      "[202, 19, 245, 202, 73]\n",
      "id: {}, dist: {} 48 2503810.2\n",
      "[294, 429, 435, 191, 17]\n",
      "id: {}, dist: {} 49 1.313034\n",
      "[165, 230, 23, 274, 453]\n",
      "id: {}, dist: {} 50 1.1305068\n",
      "[95, 435, 460, 230, 17]\n",
      "id: {}, dist: {} 51 1.2099935\n",
      "[165, 230, 23, 274, 202]\n",
      "id: {}, dist: {} 52 1.1345941\n",
      "[453, 85, 230, 23, 99]\n",
      "id: {}, dist: {} 53 1.1422483\n",
      "[327, 230, 276, 344, 26]\n",
      "id: {}, dist: {} 54 2.2374237\n",
      "[94, 63, 230, 63, 230]\n",
      "id: {}, dist: {} 55 8670456.0\n",
      "[165, 230, 23, 274, 30]\n",
      "id: {}, dist: {} 56 1.1282793\n",
      "[138, 230, 202, 23, 274]\n",
      "id: {}, dist: {} 57 1.1404012\n",
      "[294, 122, 429, 435, 191]\n",
      "id: {}, dist: {} 58 1.2410926\n",
      "[366, 151, 230, 199, 19]\n",
      "id: {}, dist: {} 59 1.9202334\n",
      "[373, 230, 202, 23, 138]\n",
      "id: {}, dist: {} 60 1.1624602\n",
      "[138, 230, 362, 30, 453]\n",
      "id: {}, dist: {} 61 1.245018\n",
      "[138, 219, 393, 230, 498]\n",
      "id: {}, dist: {} 62 1.1514045\n",
      "[165, 230, 202, 23, 138]\n",
      "id: {}, dist: {} 63 1.1364114\n",
      "[138, 230, 30, 362, 453]\n",
      "id: {}, dist: {} 64 1.1698759\n",
      "[17, 230, 202, 258, 99]\n",
      "id: {}, dist: {} 65 1.376723\n",
      "[138, 230, 202, 30, 230]\n",
      "id: {}, dist: {} 66 2458789.8\n",
      "[373, 230, 202, 23, 138]\n",
      "id: {}, dist: {} 67 1.1624874\n",
      "[145, 380, 63, 230, 359]\n",
      "id: {}, dist: {} 68 2.149442\n",
      "[359, 380, 230, 63, 199]\n",
      "id: {}, dist: {} 69 2.2969913\n",
      "[359, 51, 230, 63, 94]\n",
      "id: {}, dist: {} 70 2.523528\n",
      "[207, 230, 380, 94, 19]\n",
      "id: {}, dist: {} 71 2.4011054\n",
      "[158, 451, 51, 499, 499]\n",
      "id: {}, dist: {} 72 48199810.0\n",
      "[177, 230, 453, 230, 177]\n",
      "id: {}, dist: {} 73 713757.0\n",
      "[165, 401, 230, 23, 202]\n",
      "id: {}, dist: {} 74 1.1484989\n",
      "[165, 230, 23, 435, 30]\n",
      "id: {}, dist: {} 75 1.1259141\n",
      "[429, 435, 191, 17, 187]\n",
      "id: {}, dist: {} 76 1.2987489\n",
      "[373, 230, 202, 23, 138]\n",
      "id: {}, dist: {} 77 1.1638218\n",
      "[435, 230, 202, 23, 138]\n",
      "id: {}, dist: {} 78 1.1667376\n",
      "[498, 230, 202, 323, 20]\n",
      "id: {}, dist: {} 79 1.2154373\n",
      "[63, 499, 451, 51, 94]\n",
      "id: {}, dist: {} 80 2.4568644\n",
      "[138, 202, 23, 230, 274]\n",
      "id: {}, dist: {} 81 1.1466733\n",
      "[202, 19, 202, 73, 202]\n",
      "id: {}, dist: {} 82 2657079500000.0\n",
      "[453, 230, 393, 85, 99]\n",
      "id: {}, dist: {} 83 1.1310018\n",
      "[359, 380, 327, 230, 94]\n",
      "id: {}, dist: {} 84 2.5204377\n",
      "[160, 230, 202, 453, 23]\n",
      "id: {}, dist: {} 85 1.1578388\n",
      "[418, 230, 380, 94, 151]\n",
      "id: {}, dist: {} 86 1.846012\n",
      "[135, 230, 453, 317, 69]\n",
      "id: {}, dist: {} 87 1.5216143\n",
      "[37, 429, 453, 247, 230]\n",
      "id: {}, dist: {} 88 1.1852214\n",
      "[276, 230, 453, 51, 453]\n",
      "id: {}, dist: {} 89 135784.2\n",
      "[145, 380, 19, 202, 199]\n",
      "id: {}, dist: {} 90 2.0575814\n",
      "[130, 51, 19, 230, 202]\n",
      "id: {}, dist: {} 91 2.0442684\n",
      "[202, 138, 23, 230, 274]\n",
      "id: {}, dist: {} 92 1.1572616\n",
      "[38, 30, 207, 230, 388]\n",
      "id: {}, dist: {} 93 1.0866115\n",
      "[94, 63, 94, 230, 94]\n",
      "id: {}, dist: {} 94 21523073000000.0\n",
      "[301, 453, 230, 51, 1]\n",
      "id: {}, dist: {} 95 1.6750147\n",
      "[457, 230, 202, 23, 138]\n",
      "id: {}, dist: {} 96 1.1623696\n",
      "[373, 230, 202, 23, 138]\n",
      "id: {}, dist: {} 97 1.1585838\n",
      "[165, 23, 274, 230, 138]\n",
      "id: {}, dist: {} 98 1.1304694\n",
      "[202, 17, 230, 417, 467]\n",
      "id: {}, dist: {} 99 1.697172\n",
      "[202, 429, 453, 230, 37]\n",
      "id: {}, dist: {} 100 1.436771\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 101 9610765000000.0\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 102 10010168000000.0\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 103 11418011000000.0\n",
      "[202, 429, 453, 230, 17]\n",
      "id: {}, dist: {} 104 1.570083\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 105 9973564000000.0\n",
      "[71, 17, 202, 224, 429]\n",
      "id: {}, dist: {} 106 1.8171755\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 107 11094164000000.0\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 108 8953219000000.0\n",
      "[289, 289, 289, 46, 46]\n",
      "id: {}, dist: {} 109 86098.234\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 110 11300188000000.0\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 111 8944575000000.0\n",
      "[72, 429, 202, 439, 17]\n",
      "id: {}, dist: {} 112 1.6438924\n",
      "[202, 429, 177, 99, 230]\n",
      "id: {}, dist: {} 113 1.5403123\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 114 10303558000000.0\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 115 9701451000000.0\n",
      "[453, 17, 202, 368, 429]\n",
      "id: {}, dist: {} 116 1.8357471\n",
      "[230, 493, 246, 390, 483]\n",
      "id: {}, dist: {} 117 3.1915612\n",
      "[202, 19, 323, 202, 46]\n",
      "id: {}, dist: {} 118 2948402.5\n",
      "[71, 17, 224, 429, 453]\n",
      "id: {}, dist: {} 119 1.7581557\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 120 9743482000000.0\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 121 6376592000000.0\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 122 9853333000000.0\n",
      "[453, 17, 202, 368, 429]\n",
      "id: {}, dist: {} 123 1.7877284\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 124 9876301000000.0\n",
      "[71, 230, 202, 429, 221]\n",
      "id: {}, dist: {} 125 1.6617864\n",
      "[71, 323, 202, 429, 230]\n",
      "id: {}, dist: {} 126 1.6827409\n",
      "[453, 17, 202, 368, 429]\n",
      "id: {}, dist: {} 127 1.6713128\n",
      "[368, 184, 326, 230, 202]\n",
      "id: {}, dist: {} 128 1.1985339\n",
      "[71, 230, 30, 429, 221]\n",
      "id: {}, dist: {} 129 1.5031123\n",
      "[99, 202, 323, 429, 230]\n",
      "id: {}, dist: {} 130 1.5298141\n",
      "[453, 17, 435, 85, 187]\n",
      "id: {}, dist: {} 131 1.2203244\n",
      "[265, 277, 454, 401, 454]\n",
      "id: {}, dist: {} 132 399834.5\n",
      "[202, 429, 149, 453, 17]\n",
      "id: {}, dist: {} 133 1.6891444\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 134 10218762000000.0\n",
      "[71, 17, 224, 429, 30]\n",
      "id: {}, dist: {} 135 1.822824\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 136 6007279000000.0\n",
      "[99, 202, 323, 230, 429]\n",
      "id: {}, dist: {} 137 1.5412695\n",
      "[453, 323, 202, 429, 219]\n",
      "id: {}, dist: {} 138 1.6493789\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 139 10095932000000.0\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 140 8480936000000.0\n",
      "[202, 19, 323, 202, 46]\n",
      "id: {}, dist: {} 141 2657431.5\n",
      "[202, 429, 453, 37, 230]\n",
      "id: {}, dist: {} 142 1.4400933\n",
      "[202, 429, 177, 71, 230]\n",
      "id: {}, dist: {} 143 1.5304714\n",
      "[202, 19, 323, 202, 202]\n",
      "id: {}, dist: {} 144 8997333000000.0\n",
      "[453, 17, 202, 368, 429]\n",
      "id: {}, dist: {} 145 1.5573211\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "re = torch.zeros([len(test_x), 2], dtype=torch.float32)\n",
    "for ids, vector in enumerate(test_x):\n",
    "    v = vector.unsqueeze(0)\n",
    "    c = OMP(v, train_x[:500][:], 5, 0.001)\n",
    "    t = v - torch.mm(c, train_x[:500][:])\n",
    "    distance = np.linalg.norm(t)\n",
    "    print(\"id: {}, dist: {}\", ids, distance)\n",
    "    if distance < 10000.0:\n",
    "        re[ids][0] = 1.0\n",
    "    else:\n",
    "        re[ids][1] = 1.0\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.7534\n"
     ]
    }
   ],
   "source": [
    "total = len(test_x)\n",
    "correct = 0.0\n",
    "_, pred = torch.max(re, 1)\n",
    "v, label = torch.max(test_y, 1)\n",
    "correct+= float((pred == label).sum())\n",
    "accuracy = float(100*(correct/total))\n",
    "print('Accuracy: {:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pysyft] *",
   "language": "python",
   "name": "conda-env-Pysyft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
