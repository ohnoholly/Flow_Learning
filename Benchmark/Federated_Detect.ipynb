{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Pysyft/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/Pysyft/lib/python3.6/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import Sklearn_PyTorch\n",
    "\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(df): \n",
    "    x = df.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df = pd.DataFrame(x_scaled)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming categorical feature to numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoding(data):\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == type(object):\n",
    "            le_x = preprocessing.LabelEncoder()\n",
    "            le_x.fit(data[col])\n",
    "            data[col] = le_x.transform(data[col])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def label_encoder(df):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(df)\n",
    "    print(enc.categories_)\n",
    "    df_array = enc.transform(df).toarray() #Encode the classes to a binary array \n",
    "    return df_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACM KDD'99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../../../Dataset/KDD99/kddcup99.csv\"\n",
    "\n",
    "dataset = pd.read_csv(data_path, sep=',', usecols=range(0, 42))\n",
    "\n",
    "print(\"Dataset Shape:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Randomly split data into three parts\n",
    "data_server = dataset.sample(frac=0.5, random_state=1)\n",
    "dataset = dataset.drop(data_server.index)\n",
    "data_alice = dataset.sample(frac=0.5, random_state=1)\n",
    "data_bob = dataset.drop(data_alice.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Divide data into x and y\n",
    "data_server_x = pd.DataFrame(data_server.iloc[:, 0:41])\n",
    "data_server_y = pd.DataFrame(data_server.iloc[:, 41])\n",
    "data_alice_x = pd.DataFrame(data_alice.iloc[:, 0:41])\n",
    "data_alice_y = pd.DataFrame(data_alice.iloc[:, 41])\n",
    "data_bob_x = pd.DataFrame(data_bob.iloc[:, 0:41])\n",
    "data_bob_y = pd.DataFrame(data_bob.iloc[:, 41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Relabel data into biclasses\n",
    "new_class = {'back':'abnormal', 'buffer_overflow':'abnormal', 'ftp_write':'abnormal', 'guess_passwd':'abnormal', 'imap':'abnormal',\n",
    "            'ipsweep':'abnormal', 'land':'abnormal', 'loadmodule':'abnormal', 'multihop':'abnormal', 'neptune':'abnormal', 'nmap':'abnormal',\n",
    "            'perl':'abnormal', 'phf':'abnormal', 'pod':'abnormal', 'portsweep':'abnormal', 'rootkit':'abnormal', 'satan':'abnormal',\n",
    "            'smurf':'abnormal', 'spy':'abnormal', 'teardrop':'abnormal', 'warezclient':'abnormal', 'warezmaster':'abnormal'}\n",
    "data_server_y = data_server_y.replace(new_class)\n",
    "data_alice_y = data_alice_y.replace(new_class)\n",
    "data_bob_y = data_bob_y.replace(new_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode the string datatype to numerial\n",
    "data_server_x = encoding(data_server_x)\n",
    "data_server_y = encoding(data_server_y)\n",
    "data_alice_x = encoding(data_alice_x)\n",
    "data_alice_y = encoding(data_alice_y)\n",
    "data_bob_x = encoding(data_bob_x)\n",
    "data_bob_y = encoding(data_bob_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize x data\n",
    "data_server_x = normalize(data_server_x)\n",
    "data_alice_x = normalize(data_alice_x)\n",
    "data_bob_x = normalize(data_bob_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One-Hot encoding labels\n",
    "data_server_y = label_encoder(data_server_y)\n",
    "data_alice_y = label_encoder(data_alice_y)\n",
    "data_bob_y = label_encoder(data_bob_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data_server_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IoT Botnet Stream Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all the data from the CSV file \n",
    "BM_DATA_PATH = \"../../../Dataset/Botnet_Detection/Philips_B120N10_Baby_Monitor\"\n",
    "DB_DATA_PATH = \"../../../Dataset/Botnet_Detection/Danmini_Doorbell\"\n",
    "ET_DATA_PATH = \"../../../Dataset/Botnet_Detection/Ecobee_Thermostat\"\n",
    "PT_DATA_PATH = \"../../../Dataset/Botnet_Detection/PT_838_Security Camera\"\n",
    "XC_DATA_PATH = \"../../../Dataset/Botnet_Detection/XCS7_1002_WHT_Security_Camera\"\n",
    "df_bm_b = pd.read_csv(BM_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_bm_m = pd.read_csv(BM_DATA_PATH+\"/Mirai/udp.csv\")\n",
    "df_db_b = pd.read_csv(DB_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_db_m = pd.read_csv(DB_DATA_PATH+\"/Mirai/udp.csv\")\n",
    "df_et_b = pd.read_csv(ET_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_et_m = pd.read_csv(ET_DATA_PATH+\"/Mirai/udp.csv\")\n",
    "df_pt_b = pd.read_csv(ET_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_pt_m = pd.read_csv(ET_DATA_PATH+\"/Mirai/udp.csv\")\n",
    "df_xc_b = pd.read_csv(XC_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_xc_m = pd.read_csv(XC_DATA_PATH+\"/Mirai/udp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assign the label to each dataframe\n",
    "df_bm_b = df_bm_b.assign(label = 'b') \n",
    "df_db_b = df_db_b.assign(label = 'b') \n",
    "df_et_b = df_et_b.assign(label = 'b')\n",
    "df_pt_b = df_pt_b.assign(label = 'b')\n",
    "df_xc_b = df_xc_b.assign(label = 'b')\n",
    "df_bm_m = df_bm_m.assign(label = 'm')\n",
    "df_db_m = df_db_m.assign(label = 'm') \n",
    "df_et_m = df_et_m.assign(label = 'm') \n",
    "df_pt_m = df_pt_m.assign(label = 'm')\n",
    "df_xc_m = df_xc_m.assign(label = 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151481, 116)\n",
      "(13113, 116)\n",
      "(151879, 116)\n",
      "(46585, 116)\n"
     ]
    }
   ],
   "source": [
    "print(df_pt_m.shape)\n",
    "print(df_pt_b.shape)\n",
    "print(df_xc_m.shape)\n",
    "print(df_xc_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combine the benign traffic and malicious traffic\n",
    "df_bm = df_bm_b\n",
    "df_bm = df_bm.append(df_bm_m, ignore_index = True)\n",
    "df_db = df_db_b\n",
    "df_db = df_db.append(df_db_m, ignore_index = True)\n",
    "df_et = df_et_b\n",
    "df_et = df_et.append(df_et_m, ignore_index = True)\n",
    "df_pt = df_pt_b\n",
    "df_pt = df_pt.append(df_pt_m, ignore_index = True)\n",
    "df_xc = df_xc_b\n",
    "df_xc = df_xc.append(df_xc_m, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffler(df):\n",
    "  return df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle the rows in dataframe\n",
    "df_bm = shuffler(df_bm)\n",
    "df_db = shuffler(df_db)\n",
    "df_et = shuffler(df_et)\n",
    "df_pt = shuffler(df_pt)\n",
    "df_xc = shuffler(df_xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dataset on server for initial model (second version)\n",
    "df_server = pd.DataFrame()\n",
    "df_server = df_server.append(df_et.sample(frac =.25), ignore_index=True)\n",
    "df_server = df_server.append(df_pt.sample(frac =.25), ignore_index=True)\n",
    "df_server = df_server.append(df_xc.sample(frac =.25), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dataset on server for initial model (first version)\n",
    "df_server = pd.DataFrame()\n",
    "df_server = df_server.append(df_bm.sample(frac =.25), ignore_index=True)\n",
    "df_server = df_server.append(df_db.sample(frac =.25), ignore_index=True)\n",
    "df_server = df_server.append(df_et.sample(frac =.25), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131912, 116)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_server.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Divide dataframe into x and y\n",
    "df_s_x = pd.DataFrame(df_server.iloc[:, 0:115])\n",
    "df_s_y = pd.DataFrame(df_server.iloc[:, 115])\n",
    "df_bm_x = pd.DataFrame(df_bm.iloc[:, 0:115])\n",
    "df_bm_y = pd.DataFrame(df_bm.iloc[:, 115])\n",
    "df_db_x = pd.DataFrame(df_db.iloc[:, 0:115])\n",
    "df_db_y = pd.DataFrame(df_db.iloc[:, 115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize the x dataframe\n",
    "df_s_x = normalize(df_s_x)\n",
    "df_bm_x = normalize(df_bm_x)\n",
    "df_db_x = normalize(df_db_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392274, 116)\n"
     ]
    }
   ],
   "source": [
    "print(df_bm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131912, 115)\n"
     ]
    }
   ],
   "source": [
    "print(df_s_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287213, 115)\n"
     ]
    }
   ],
   "source": [
    "print(df_db_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['b', 'm'], dtype=object)]\n",
      "[array(['b', 'm'], dtype=object)]\n",
      "[array(['b', 'm'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "#One-Hot encoding labels and transform into array\n",
    "s_y = label_encoder(df_s_y)\n",
    "bm_y = label_encoder(df_bm_y)\n",
    "db_y = label_encoder(df_db_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Transfering data to workers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ELM(torch.nn.Module):\n",
    "    def __init__(self, n_inputs: int, hidden_units = 1000):\n",
    "        self.random_weights = np.random.normal(size=[n_inputs, hidden_units]) # A random weight is assigned\n",
    "    \n",
    "    def learn(self, X: np.ndarray, Y: np.ndarray):\n",
    "        H = self._hidden_layer(X)\n",
    "        self.output_weights = np.linalg.pinv(H) @ Y\n",
    "    \n",
    "    def _f(self, x: np.ndarray): \n",
    "        return 1. / (1. + np.exp(-x)) #activation function: sigmoid\n",
    "    \n",
    "    def _hidden_layer(self, inputs: np.ndarray): \n",
    "        return self._f(inputs @ self.random_weights)\n",
    "  \n",
    "    def _output_layer(self, hidden: np.ndarray): \n",
    "        return hidden @ self.output_weights\n",
    "  \n",
    "    def __call__(self, inputs: np.ndarray):  #infer\n",
    "        return self._output_layer(self._hidden_layer(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_dim, h_dim, out_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(in_dim, h_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(h_dim)\n",
    "        self.linear2 = torch.nn.Linear(h_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IoT BotNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BM = sy.VirtualWorker(hook, id='BM')\n",
    "DB = sy.VirtualWorker(hook, id='DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "b_train_x, b_test_x, b_train_y, b_test_y = train_test_split(df_bm_x, bm_y, test_size=0.20)\n",
    "d_train_x, d_test_x, d_train_y, d_test_y = train_test_split(df_db_x, db_y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_server_x = torch.FloatTensor(df_s_x.values.astype(np.float32))\n",
    "tensor_server_y = torch.FloatTensor(s_y.astype(np.float32))\n",
    "t_b_train_x = torch.FloatTensor(b_train_x.values.astype(np.float32))\n",
    "t_b_test_x = torch.tensor(b_test_x.values.astype(np.float32))\n",
    "t_b_train_y = torch.tensor(b_train_y.astype(np.float32))\n",
    "t_b_test_y = torch.tensor(b_test_y.astype(np.float32))\n",
    "t_d_train_x = torch.tensor(d_train_x.values.astype(np.float32))\n",
    "t_d_test_x = torch.tensor(d_test_x.values.astype(np.float32))\n",
    "t_d_train_y = torch.tensor(d_train_y.astype(np.float32))\n",
    "t_d_test_y = torch.tensor(d_test_y.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([229770, 115])\n",
      "torch.Size([57443, 115])\n"
     ]
    }
   ],
   "source": [
    "print(t_d_train_x.shape)\n",
    "print(t_d_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_x_train_ptr = t_b_train_x.send(BM)\n",
    "b_x_test_ptr = t_b_test_x.send(BM)\n",
    "b_y_train_ptr = t_b_train_y.send(BM)\n",
    "b_y_test_ptr = t_b_test_y.send(BM)\n",
    "d_x_train_ptr = t_d_train_x.send(DB)\n",
    "d_x_test_ptr = t_d_test_x.send(DB)\n",
    "d_y_train_ptr = t_d_train_y.send(DB)\n",
    "d_y_test_ptr = t_d_test_y.send(DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ACM KDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Alice = sy.VirtualWorker(hook, id='Alice')\n",
    "Bob = sy.VirtualWorker(hook, id='Bob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "a_train_x, a_test_x, a_train_y, a_test_y = train_test_split(data_alice_x, data_alice_y, test_size=0.20)\n",
    "b_train_x, b_test_x, b_train_y, b_test_y = train_test_split(data_bob_x, data_bob_y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_server_x = torch.FloatTensor(data_server_x.values.astype(np.float32))\n",
    "tensor_server_y = torch.FloatTensor(data_server_y.values.astype(np.float32))\n",
    "t_a_train_x = torch.tensor(a_train_x.values.astype(np.float32))\n",
    "t_a_test_x = torch.tensor(a_test_x.values.astype(np.float32))\n",
    "t_a_train_y = torch.tensor(a_train_y.values.astype(np.float32))\n",
    "t_a_test_y = torch.tensor(a_test_y.values.astype(np.float32))\n",
    "t_b_train_x = torch.FloatTensor(b_train_x.values.astype(np.float32))\n",
    "t_b_test_x = torch.tensor(b_test_x.values.astype(np.float32))\n",
    "t_b_train_y = torch.tensor(b_train_y.values.astype(np.float32))\n",
    "t_b_test_y = torch.tensor(b_test_y.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(t_b_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_x_train_ptr = t_a_train_x.send(Alice)\n",
    "a_x_test_ptr = t_a_test_x.send(Alice)\n",
    "a_y_train_ptr = t_a_train_y.send(Alice)\n",
    "a_y_test_ptr = t_a_test_y.send(Alice)\n",
    "b_x_train_ptr = t_b_train_x.send(Bob)\n",
    "b_x_test_ptr = t_b_test_x.send(Bob)\n",
    "b_y_train_ptr = t_b_train_y.send(Bob)\n",
    "b_y_test_ptr = t_b_test_y.send(Bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Bob._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Alice._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tensor_server_x)\n",
    "print(tensor_server_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Sklearn_PyTorch import TorchRandomForestClassifier\n",
    "\n",
    "# Initialisation of the model\n",
    "my_model = TorchRandomForestClassifier(nb_trees=100, nb_samples=3, max_depth=5, bootstrap=True)\n",
    "\n",
    "# Fitting function\n",
    "my_model.fit(tensor_server_x, tensor_server_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 600\n",
    "input_dim = 115\n",
    "output_dim = 2 #Number of clasees\n",
    "h_dim = 100\n",
    "lr_rate = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_dim, h_dim, output_dim)\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs, model, data, labels):\n",
    "    for e in range(int(epochs)):\n",
    "        y_pred = model(data)\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, labels)\n",
    "        if e % 100 == 99:\n",
    "            print(e, loss.item())\n",
    "    \n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1207.5557861328125\n",
      "199 455.7712097167969\n",
      "299 352.61712646484375\n",
      "399 539.6387329101562\n",
      "499 464.52520751953125\n",
      "599 301.3799743652344\n"
     ]
    }
   ],
   "source": [
    "training(epochs, model, tensor_server_x, tensor_server_y) ## Train the initial model on Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ELM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_server_x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=ELM(tensor_server_x.size(0), n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(epochs, model, data, labels):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_dim, output_dim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(epochs, model, data, labels):\n",
    "    for epochs in range(int(epochs)):    \n",
    "        optimizer.zero_grad() ## Zero out the gradient\n",
    "        outputs = model(data) ## Call forward\n",
    "        \n",
    "        loss = ((outputs - labels)**2).sum() ## softmax\n",
    "        if epochs % 100 == 99:\n",
    "            print(loss)\n",
    "        loss.backward() ## Accumulated gradient updates into x\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_server_y = tensor_server_y.squeeze()\n",
    "print(tensor_server_y.shape)\n",
    "training(epochs, model, tensor_server_x, tensor_server_y) ## Train the initial model on Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer model to clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IoTBot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BM_model = model.copy().send(BM)\n",
    "DB_model = model.copy().send(DB)\n",
    "\n",
    "BM_opt = torch.optim.SGD(params=BM_model.parameters(),lr=lr_rate)\n",
    "DB_opt = torch.optim.SGD(params=DB_model.parameters(),lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([78455, 2])\n",
      "torch.Size([57443, 2])\n"
     ]
    }
   ],
   "source": [
    "print(t_b_test_y.shape)\n",
    "print(t_d_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bm, y_bm = t_b_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_db, y_db = t_d_test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary Training on the device with local data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{43334435263: tensor([[3.1288e-01, 3.1749e-01, 4.8189e-02,  ..., 0.0000e+00, 5.8125e-01,\n",
      "         4.7004e-01],\n",
      "        [5.6665e-03, 4.3082e-03, 0.0000e+00,  ..., 5.1075e-04, 5.8129e-01,\n",
      "         5.2218e-01],\n",
      "        [2.8535e-01, 2.6712e-01, 9.5405e-02,  ..., 0.0000e+00, 5.8125e-01,\n",
      "         4.7004e-01],\n",
      "        ...,\n",
      "        [2.6337e-01, 1.6125e-01, 1.2721e-01,  ..., 0.0000e+00, 5.8125e-01,\n",
      "         4.7004e-01],\n",
      "        [2.2333e-03, 1.0833e-02, 1.3207e-04,  ..., 1.5083e-04, 5.8125e-01,\n",
      "         4.7202e-01],\n",
      "        [2.4926e-03, 4.5192e-03, 9.7042e-06,  ..., 4.5933e-04, 5.8125e-01,\n",
      "         4.6411e-01]]), 23054398979: tensor([[2.2030e-03, 8.5593e-03, 1.2546e-04,  ..., 1.6255e-04, 5.8128e-01,\n",
      "         5.1509e-01],\n",
      "        [3.4343e-10, 4.3082e-03, 0.0000e+00,  ..., 5.5477e-04, 5.8125e-01,\n",
      "         4.6383e-01],\n",
      "        [4.3966e-01, 1.9566e-01, 1.2690e-01,  ..., 0.0000e+00, 5.8125e-01,\n",
      "         4.7004e-01],\n",
      "        ...,\n",
      "        [3.6867e-01, 2.4843e-01, 1.0766e-01,  ..., 0.0000e+00, 5.8125e-01,\n",
      "         4.7004e-01],\n",
      "        [0.0000e+00, 4.3082e-03, 3.8264e-18,  ..., 5.3092e-02, 5.8656e-01,\n",
      "         6.0823e-01],\n",
      "        [3.2185e-01, 3.1054e-01, 5.5929e-02,  ..., 0.0000e+00, 5.8125e-01,\n",
      "         4.7004e-01]]), 35380698691: tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]), 36618230868: tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]]), 69172659437: Parameter containing:\n",
      "tensor([[-0.0711,  0.0201,  0.0296,  ...,  0.0514,  0.0682, -0.0183],\n",
      "        [-0.0481, -0.0182, -0.0785,  ...,  0.0231,  0.0040, -0.0131],\n",
      "        [-0.0713,  0.0858, -0.0526,  ...,  0.0508,  0.0708, -0.0914],\n",
      "        ...,\n",
      "        [-0.0367, -0.0481,  0.0802,  ..., -0.0067, -0.0686,  0.0327],\n",
      "        [-0.0288,  0.0460, -0.0492,  ..., -0.0192,  0.0692,  0.0855],\n",
      "        [ 0.0677,  0.0511, -0.0377,  ..., -0.0218, -0.0545, -0.0110]],\n",
      "       requires_grad=True), 46419472276: Parameter containing:\n",
      "tensor([-0.0372, -0.0508, -0.0839, -0.0283,  0.0764, -0.0712,  0.0195, -0.0098,\n",
      "         0.0958, -0.0003, -0.0213, -0.0187, -0.0764,  0.0088,  0.0154, -0.0230,\n",
      "         0.0709,  0.1061,  0.0130, -0.0669,  0.0538,  0.0537,  0.0985,  0.0595,\n",
      "        -0.0040,  0.0034, -0.0146,  0.0535, -0.0073, -0.0637,  0.0299, -0.0924,\n",
      "        -0.0833,  0.0486,  0.0848, -0.0103,  0.0017,  0.0351,  0.0382,  0.0370,\n",
      "         0.0189,  0.0457,  0.0928, -0.0278, -0.0738,  0.0687,  0.0237,  0.0352,\n",
      "        -0.0763,  0.0196, -0.0534,  0.0479, -0.0643,  0.0443,  0.0055,  0.0166,\n",
      "         0.0598,  0.0026,  0.0444,  0.0316, -0.0086, -0.0504,  0.0202,  0.0759,\n",
      "        -0.0396,  0.0790, -0.0027,  0.0400, -0.0791, -0.0511, -0.0106, -0.0674,\n",
      "        -0.0044, -0.0255,  0.0567,  0.0040, -0.0448, -0.0099, -0.0141, -0.0610,\n",
      "         0.1703,  0.1721,  0.0024, -0.0951, -0.0218, -0.0846, -0.0150,  0.0027,\n",
      "         0.0446,  0.1221, -0.0817, -0.0969, -0.0577, -0.0370, -0.0767, -0.0411,\n",
      "        -0.0290,  0.0486, -0.0838, -0.0268], requires_grad=True), 13585139202: Parameter containing:\n",
      "tensor([0.7853, 0.1596, 0.2832, 0.8330, 0.6196, 0.7084, 0.1078, 0.3614, 0.3693,\n",
      "        0.8225, 0.6914, 0.3603, 0.7897, 0.0439, 0.6569, 0.8381, 0.2988, 0.6491,\n",
      "        0.3299, 0.7412, 0.2569, 0.4909, 0.2270, 0.7527, 0.4769, 0.4406, 0.9648,\n",
      "        0.5462, 0.6744, 0.7970, 0.2874, 0.2003, 0.0394, 0.9203, 0.4080, 0.9038,\n",
      "        0.4517, 0.7492, 0.3410, 0.5628, 0.9160, 0.6731, 0.5608, 0.7517, 0.6072,\n",
      "        0.8576, 0.7042, 0.7655, 0.6890, 0.8890, 0.0812, 0.8079, 0.9239, 0.8952,\n",
      "        0.9011, 0.8411, 0.6695, 0.3256, 0.4438, 0.6284, 0.7418, 0.7831, 0.2181,\n",
      "        0.2975, 0.4542, 0.1206, 0.7828, 0.4027, 0.4397, 0.3244, 0.4629, 0.2045,\n",
      "        0.3487, 0.4297, 0.3412, 0.4625, 0.3124, 0.1364, 0.4072, 0.2955, 0.6903,\n",
      "        0.3958, 0.3479, 0.9264, 0.6043, 0.1501, 0.5724, 0.3192, 0.6036, 0.0844,\n",
      "        0.7253, 0.3322, 0.4237, 0.5088, 0.5016, 0.7155, 0.2890, 0.2430, 0.2117,\n",
      "        0.0796], requires_grad=True), 45426966329: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.], requires_grad=True), 80710857501: Parameter containing:\n",
      "tensor([[ 0.0073, -0.0410,  0.0259,  0.0230,  0.0986,  0.0058, -0.0254, -0.1201,\n",
      "          0.1532,  0.0995,  0.0404,  0.0374, -0.0197,  0.1434,  0.1892,  0.1118,\n",
      "          0.0699,  0.0977, -0.0924, -0.0592,  0.0687,  0.0113,  0.1022, -0.0441,\n",
      "          0.0510, -0.0692, -0.0476,  0.0731, -0.0131,  0.0995,  0.0721, -0.1436,\n",
      "         -0.0846,  0.0403,  0.0487,  0.0484, -0.0159, -0.0934, -0.0612,  0.0856,\n",
      "         -0.0539,  0.0813,  0.1284, -0.0365, -0.0238, -0.0102,  0.0178,  0.2176,\n",
      "         -0.0599, -0.1089, -0.0939,  0.0476, -0.0722, -0.0859, -0.0287, -0.0679,\n",
      "         -0.0824, -0.0438, -0.0376,  0.1467, -0.0304, -0.0490,  0.0048,  0.1656,\n",
      "         -0.0571, -0.0687, -0.0839, -0.0796,  0.0008, -0.0493,  0.0696, -0.0179,\n",
      "          0.0750, -0.0985,  0.0337,  0.0328,  0.0882,  0.0905, -0.1815, -0.0460,\n",
      "          0.1598,  0.2455,  0.1915, -0.0467,  0.0183, -0.0572,  0.0198, -0.0109,\n",
      "         -0.1213,  0.1177,  0.0677, -0.0196,  0.0549,  0.0363,  0.0324,  0.0013,\n",
      "         -0.0047,  0.0363, -0.0856,  0.0131],\n",
      "        [ 0.0621, -0.0496, -0.0397,  0.0978, -0.0021,  0.0125,  0.0521, -0.0289,\n",
      "         -0.0476, -0.0135,  0.0863,  0.0469,  0.0836,  0.0471, -0.1121,  0.1291,\n",
      "          0.0142,  0.0072,  0.0723, -0.0135, -0.1439,  0.0440, -0.0224,  0.0397,\n",
      "         -0.0763, -0.0791, -0.0399, -0.0006,  0.0558, -0.0735,  0.0196,  0.1291,\n",
      "          0.0546,  0.0642, -0.0124,  0.0371,  0.0622,  0.0390, -0.0283,  0.1461,\n",
      "          0.1647, -0.0347, -0.0275, -0.0162, -0.0050,  0.0572, -0.0178, -0.1027,\n",
      "         -0.0437,  0.0922, -0.0114,  0.0232, -0.0049, -0.0063, -0.0431, -0.0669,\n",
      "          0.0746, -0.0359,  0.1142, -0.0136, -0.0460, -0.0797,  0.0132, -0.0937,\n",
      "          0.0283, -0.0622,  0.0472,  0.0879,  0.0628, -0.0958, -0.0243,  0.0375,\n",
      "         -0.0975,  0.0168,  0.0059, -0.0787, -0.0343, -0.0693,  0.1534,  0.0096,\n",
      "         -0.2467, -0.1281, -0.1861, -0.0442,  0.1545,  0.0323,  0.0257,  0.0718,\n",
      "          0.1009, -0.1312, -0.0426,  0.0601, -0.0161, -0.0222,  0.0566,  0.1111,\n",
      "          0.0986,  0.0938, -0.0766, -0.0597]], requires_grad=True), 75153945381: Parameter containing:\n",
      "tensor([0.3071, 0.2883], requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "print(BM._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{73179098599: tensor([[5.1555e-01, 3.5484e-01, 9.0959e-01,  ..., 0.0000e+00, 1.3573e-01,\n",
      "         1.4862e-01],\n",
      "        [4.6970e-01, 3.9699e-01, 9.5279e-01,  ..., 0.0000e+00, 1.3573e-01,\n",
      "         1.4862e-01],\n",
      "        [4.6528e-01, 5.2962e-01, 9.9804e-01,  ..., 0.0000e+00, 1.3573e-01,\n",
      "         1.4862e-01],\n",
      "        ...,\n",
      "        [0.0000e+00, 7.8029e-02, 0.0000e+00,  ..., 3.7402e-16, 1.3573e-01,\n",
      "         1.4862e-01],\n",
      "        [3.4889e-01, 7.1069e-01, 8.3803e-01,  ..., 0.0000e+00, 1.3573e-01,\n",
      "         1.4862e-01],\n",
      "        [4.6934e-01, 3.7863e-01, 9.3574e-01,  ..., 0.0000e+00, 1.3573e-01,\n",
      "         1.4862e-01]]), 56823256256: tensor([[3.0312e-01, 4.3411e-01, 9.7924e-01,  ..., 0.0000e+00, 1.3573e-01,\n",
      "         1.4862e-01],\n",
      "        [1.1648e-02, 8.6243e-02, 5.9663e-17,  ..., 3.7402e-16, 1.3573e-01,\n",
      "         1.4862e-01],\n",
      "        [3.2187e-01, 7.8774e-01, 6.9402e-01,  ..., 0.0000e+00, 1.3573e-01,\n",
      "         1.4862e-01],\n",
      "        ...,\n",
      "        [3.6130e-01, 6.4701e-01, 9.2400e-01,  ..., 0.0000e+00, 1.3573e-01,\n",
      "         1.4862e-01],\n",
      "        [5.0682e-01, 3.5740e-01, 9.1278e-01,  ..., 0.0000e+00, 1.3573e-01,\n",
      "         1.4862e-01],\n",
      "        [5.1885e-01, 4.3134e-01, 9.7763e-01,  ..., 0.0000e+00, 1.3573e-01,\n",
      "         1.4862e-01]]), 74765670785: tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]]), 89133378921: tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]]), 30936880123: Parameter containing:\n",
      "tensor([[-0.0711,  0.0201,  0.0296,  ...,  0.0514,  0.0682, -0.0183],\n",
      "        [-0.0481, -0.0182, -0.0785,  ...,  0.0231,  0.0040, -0.0131],\n",
      "        [-0.0713,  0.0858, -0.0526,  ...,  0.0508,  0.0708, -0.0914],\n",
      "        ...,\n",
      "        [-0.0367, -0.0481,  0.0802,  ..., -0.0067, -0.0686,  0.0327],\n",
      "        [-0.0288,  0.0460, -0.0492,  ..., -0.0192,  0.0692,  0.0855],\n",
      "        [ 0.0677,  0.0511, -0.0377,  ..., -0.0218, -0.0545, -0.0110]],\n",
      "       requires_grad=True), 20654136705: Parameter containing:\n",
      "tensor([-0.0372, -0.0508, -0.0839, -0.0283,  0.0764, -0.0712,  0.0195, -0.0098,\n",
      "         0.0958, -0.0003, -0.0213, -0.0187, -0.0764,  0.0088,  0.0154, -0.0230,\n",
      "         0.0709,  0.1061,  0.0130, -0.0669,  0.0538,  0.0537,  0.0985,  0.0595,\n",
      "        -0.0040,  0.0034, -0.0146,  0.0535, -0.0073, -0.0637,  0.0299, -0.0924,\n",
      "        -0.0833,  0.0486,  0.0848, -0.0103,  0.0017,  0.0351,  0.0382,  0.0370,\n",
      "         0.0189,  0.0457,  0.0928, -0.0278, -0.0738,  0.0687,  0.0237,  0.0352,\n",
      "        -0.0763,  0.0196, -0.0534,  0.0479, -0.0643,  0.0443,  0.0055,  0.0166,\n",
      "         0.0598,  0.0026,  0.0444,  0.0316, -0.0086, -0.0504,  0.0202,  0.0759,\n",
      "        -0.0396,  0.0790, -0.0027,  0.0400, -0.0791, -0.0511, -0.0106, -0.0674,\n",
      "        -0.0044, -0.0255,  0.0567,  0.0040, -0.0448, -0.0099, -0.0141, -0.0610,\n",
      "         0.1703,  0.1721,  0.0024, -0.0951, -0.0218, -0.0846, -0.0150,  0.0027,\n",
      "         0.0446,  0.1221, -0.0817, -0.0969, -0.0577, -0.0370, -0.0767, -0.0411,\n",
      "        -0.0290,  0.0486, -0.0838, -0.0268], requires_grad=True), 70766611171: Parameter containing:\n",
      "tensor([0.7853, 0.1596, 0.2832, 0.8330, 0.6196, 0.7084, 0.1078, 0.3614, 0.3693,\n",
      "        0.8225, 0.6914, 0.3603, 0.7897, 0.0439, 0.6569, 0.8381, 0.2988, 0.6491,\n",
      "        0.3299, 0.7412, 0.2569, 0.4909, 0.2270, 0.7527, 0.4769, 0.4406, 0.9648,\n",
      "        0.5462, 0.6744, 0.7970, 0.2874, 0.2003, 0.0394, 0.9203, 0.4080, 0.9038,\n",
      "        0.4517, 0.7492, 0.3410, 0.5628, 0.9160, 0.6731, 0.5608, 0.7517, 0.6072,\n",
      "        0.8576, 0.7042, 0.7655, 0.6890, 0.8890, 0.0812, 0.8079, 0.9239, 0.8952,\n",
      "        0.9011, 0.8411, 0.6695, 0.3256, 0.4438, 0.6284, 0.7418, 0.7831, 0.2181,\n",
      "        0.2975, 0.4542, 0.1206, 0.7828, 0.4027, 0.4397, 0.3244, 0.4629, 0.2045,\n",
      "        0.3487, 0.4297, 0.3412, 0.4625, 0.3124, 0.1364, 0.4072, 0.2955, 0.6903,\n",
      "        0.3958, 0.3479, 0.9264, 0.6043, 0.1501, 0.5724, 0.3192, 0.6036, 0.0844,\n",
      "        0.7253, 0.3322, 0.4237, 0.5088, 0.5016, 0.7155, 0.2890, 0.2430, 0.2117,\n",
      "        0.0796], requires_grad=True), 82128409590: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.], requires_grad=True), 2604718967: Parameter containing:\n",
      "tensor([[ 0.0073, -0.0410,  0.0259,  0.0230,  0.0986,  0.0058, -0.0254, -0.1201,\n",
      "          0.1532,  0.0995,  0.0404,  0.0374, -0.0197,  0.1434,  0.1892,  0.1118,\n",
      "          0.0699,  0.0977, -0.0924, -0.0592,  0.0687,  0.0113,  0.1022, -0.0441,\n",
      "          0.0510, -0.0692, -0.0476,  0.0731, -0.0131,  0.0995,  0.0721, -0.1436,\n",
      "         -0.0846,  0.0403,  0.0487,  0.0484, -0.0159, -0.0934, -0.0612,  0.0856,\n",
      "         -0.0539,  0.0813,  0.1284, -0.0365, -0.0238, -0.0102,  0.0178,  0.2176,\n",
      "         -0.0599, -0.1089, -0.0939,  0.0476, -0.0722, -0.0859, -0.0287, -0.0679,\n",
      "         -0.0824, -0.0438, -0.0376,  0.1467, -0.0304, -0.0490,  0.0048,  0.1656,\n",
      "         -0.0571, -0.0687, -0.0839, -0.0796,  0.0008, -0.0493,  0.0696, -0.0179,\n",
      "          0.0750, -0.0985,  0.0337,  0.0328,  0.0882,  0.0905, -0.1815, -0.0460,\n",
      "          0.1598,  0.2455,  0.1915, -0.0467,  0.0183, -0.0572,  0.0198, -0.0109,\n",
      "         -0.1213,  0.1177,  0.0677, -0.0196,  0.0549,  0.0363,  0.0324,  0.0013,\n",
      "         -0.0047,  0.0363, -0.0856,  0.0131],\n",
      "        [ 0.0621, -0.0496, -0.0397,  0.0978, -0.0021,  0.0125,  0.0521, -0.0289,\n",
      "         -0.0476, -0.0135,  0.0863,  0.0469,  0.0836,  0.0471, -0.1121,  0.1291,\n",
      "          0.0142,  0.0072,  0.0723, -0.0135, -0.1439,  0.0440, -0.0224,  0.0397,\n",
      "         -0.0763, -0.0791, -0.0399, -0.0006,  0.0558, -0.0735,  0.0196,  0.1291,\n",
      "          0.0546,  0.0642, -0.0124,  0.0371,  0.0622,  0.0390, -0.0283,  0.1461,\n",
      "          0.1647, -0.0347, -0.0275, -0.0162, -0.0050,  0.0572, -0.0178, -0.1027,\n",
      "         -0.0437,  0.0922, -0.0114,  0.0232, -0.0049, -0.0063, -0.0431, -0.0669,\n",
      "          0.0746, -0.0359,  0.1142, -0.0136, -0.0460, -0.0797,  0.0132, -0.0937,\n",
      "          0.0283, -0.0622,  0.0472,  0.0879,  0.0628, -0.0958, -0.0243,  0.0375,\n",
      "         -0.0975,  0.0168,  0.0059, -0.0787, -0.0343, -0.0693,  0.1534,  0.0096,\n",
      "         -0.2467, -0.1281, -0.1861, -0.0442,  0.1545,  0.0323,  0.0257,  0.0718,\n",
      "          0.1009, -0.1312, -0.0426,  0.0601, -0.0161, -0.0222,  0.0566,  0.1111,\n",
      "          0.0986,  0.0938, -0.0766, -0.0597]], requires_grad=True), 70802778347: Parameter containing:\n",
      "tensor([0.3071, 0.2883], requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "print(DB._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:42921292518 -> DB:19998143125]>\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/generic/pointers/object_pointer.py\", line 220, in __del__\n",
      "    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/base.py\", line 253, in send_msg\n",
      "    bin_response = self._send_msg(bin_message, location)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/virtual.py\", line 7, in _send_msg\n",
      "    return location._recv_msg(message)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/virtual.py\", line 10, in _recv_msg\n",
      "    return self.recv_msg(message)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/base.py\", line 287, in recv_msg\n",
      "    response = self._message_router[msg_type](contents)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/generic/object_storage.py\", line 123, in force_rm_obj\n",
      "    obj.child.garbage_collect_data = True\n",
      "AttributeError: 'NoneType' object has no attribute 'garbage_collect_data'\n",
      "Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:95194361692 -> DB:82079813642]>\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/generic/pointers/object_pointer.py\", line 220, in __del__\n",
      "    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/base.py\", line 253, in send_msg\n",
      "    bin_response = self._send_msg(bin_message, location)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/virtual.py\", line 7, in _send_msg\n",
      "    return location._recv_msg(message)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/virtual.py\", line 10, in _recv_msg\n",
      "    return self.recv_msg(message)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/base.py\", line 287, in recv_msg\n",
      "    response = self._message_router[msg_type](contents)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/generic/object_storage.py\", line 123, in force_rm_obj\n",
      "    obj.child.garbage_collect_data = True\n",
      "AttributeError: 'NoneType' object has no attribute 'garbage_collect_data'\n",
      "Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:48949280926 -> DB:96606154077]>\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/generic/pointers/object_pointer.py\", line 220, in __del__\n",
      "    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/base.py\", line 253, in send_msg\n",
      "    bin_response = self._send_msg(bin_message, location)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/virtual.py\", line 7, in _send_msg\n",
      "    return location._recv_msg(message)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/virtual.py\", line 10, in _recv_msg\n",
      "    return self.recv_msg(message)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/base.py\", line 287, in recv_msg\n",
      "    response = self._message_router[msg_type](contents)\n",
      "  File \"/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/generic/object_storage.py\", line 123, in force_rm_obj\n",
      "    obj.child.garbage_collect_data = True\n",
      "AttributeError: 'NoneType' object has no attribute 'garbage_collect_data'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Object \"69172659437\" not found on worker!!!You just tried to interact with an object ID:69172659437 on <VirtualWorker id:BM #objects:12> which does not exist!!! Use .send() and .get() on all your tensors to make sure they\\'reon the same machines. If you think this tensor does exist, check the ._objects dictionaryon the worker and see for yourself!!! The most common reason this error happens is because someone calls.get() on the object\\'s pointer without realizing it (which deletes the remote object and sends it to the pointer). Check your code to make sure you haven\\'t already called .get() on this pointer!!!'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/generic/object_storage.py\u001b[0m in \u001b[0;36mget_obj\u001b[0;34m(self, obj_id)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 69172659437",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-852b3701eb0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#Baby Monitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mBM_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBM_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_x_train_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Compute and print loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-0ba0ff9f36cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mh_relu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_relu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0mhandle_func_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mnew_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_command\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;31m# Put back the wrappers where needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/generic/pointers/object_pointer.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Send the command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, recipient, message, return_ids)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mResponseSignatureError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mbin_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;31m# Step 3: deserialize the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVirtualWorker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseWorker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFederatedClient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseWorker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36mrecv_msg\u001b[0;34m(self, bin_message)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;31m# Step 0: deserialize message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mmsg_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/serde/serde.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(binary, worker, details)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# as msgpack's inability to serialize torch tensors or ... or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;31m# python slice objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_detail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimple_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/serde/serde.py\u001b[0m in \u001b[0;36m_detail\u001b[0;34m(worker, obj)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \"\"\"\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdetailers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/messaging/message.py\u001b[0m in \u001b[0;36mdetail\u001b[0;34m(worker, msg_tuple)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/serde/serde.py\u001b[0m in \u001b[0;36m_detail\u001b[0;34m(worker, obj)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \"\"\"\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdetailers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/serde/native_serde.py\u001b[0m in \u001b[0;36m_detail_collection_tuple\u001b[0;34m(worker, my_tuple)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Step 1: deserialize each part of the collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_tuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mpieces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpieces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/serde/serde.py\u001b[0m in \u001b[0;36m_detail\u001b[0;34m(worker, obj)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \"\"\"\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdetailers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/serde/native_serde.py\u001b[0m in \u001b[0;36m_detail_collection_tuple\u001b[0;34m(worker, my_tuple)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Step 1: deserialize each part of the collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_tuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mpieces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpieces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/serde/serde.py\u001b[0m in \u001b[0;36m_detail\u001b[0;34m(worker, obj)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \"\"\"\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdetailers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/generic/pointers/pointer_tensor.py\u001b[0m in \u001b[0;36mdetail\u001b[0;34m(worker, tensor_tuple)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;31m# If the pointer received is pointing at the current worker, we load the tensor instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mworker_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_at_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpoint_to_attr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36mget_obj\u001b[0;34m(self, obj_id)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mobj_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mid\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mto\u001b[0m \u001b[0mlook\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \"\"\"\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0;31m# An object called with get_obj will be \"with high probability\" serialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m# and sent back, so it will be GCed but remote data is any shouldn't be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/generic/object_storage.py\u001b[0m in \u001b[0;36mget_obj\u001b[0;34m(self, obj_id)\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0;34m\"make sure you haven't already called .get() on this pointer!!!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 )\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Object \"69172659437\" not found on worker!!!You just tried to interact with an object ID:69172659437 on <VirtualWorker id:BM #objects:12> which does not exist!!! Use .send() and .get() on all your tensors to make sure they\\'reon the same machines. If you think this tensor does exist, check the ._objects dictionaryon the worker and see for yourself!!! The most common reason this error happens is because someone calls.get() on the object\\'s pointer without realizing it (which deletes the remote object and sends it to the pointer). Check your code to make sure you haven\\'t already called .get() on this pointer!!!'"
     ]
    }
   ],
   "source": [
    "for e in range(100):\n",
    "    \n",
    "    #Baby Monitor\n",
    "    BM_pred = BM_model(b_x_train_ptr)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    BM_loss = criterion(BM_pred, b_y_train_ptr)\n",
    "    \n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    BM_opt.zero_grad()\n",
    "    BM_loss.backward()\n",
    "    BM_opt.step()\n",
    "    \n",
    "    #Door Bell\n",
    "    DB_pred = BM_model(d_x_train_ptr)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    DB_loss = criterion(DB_pred, d_y_train_ptr)        \n",
    "    \n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    DB_opt.zero_grad()\n",
    "    DB_loss.backward()\n",
    "    DB_opt.step()\n",
    "    \n",
    "    if e % 100 == 99:\n",
    "        print(e, \"BM_loss:\", BM_loss.item())\n",
    "        print(e, \"DB_loss:\", DB_loss.item())\n",
    "        total_b = n_bm\n",
    "        correct = 0\n",
    "        outputs_b = BM_model(b_x_test_ptr)\n",
    "        _b, pred_b = torch.max(outputs_b.data, 1)\n",
    "        vb, labels_b = torch.max(b_y_test_ptr.data, 1)\n",
    "        correct+= (pred_b == labels_b).sum()\n",
    "        accuracy_b = 100*correct/total_b\n",
    "        print(\"Iteration:\", i, \"BM Accuracy: \", accuracy_b.get().data)\n",
    "        total_d = n_db\n",
    "        correct = 0\n",
    "        outputs_d = DB_model(d_x_test_ptr)\n",
    "        _d, pred_d = torch.max(outputs_d.data, 1)\n",
    "        vd, labels_d = torch.max(d_y_test_ptr.data, 1)\n",
    "        correct+= (pred_d == labels_d).sum()\n",
    "        accuracy_d = 100*correct/total_d\n",
    "        print(\"Iteration:\", i, \"DB Accuracy: \", accuracy_d.get().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "\n",
    "    # Train Bob's Model\n",
    "    BM_opt.zero_grad()\n",
    "    BM_pred = BM_model(b_x_train_ptr)\n",
    "    BM_loss = ((BM_pred - b_y_train_ptr)**2).sum()\n",
    "    BM_loss.backward()\n",
    "\n",
    "    BM_opt.step()\n",
    "    BM_loss = BM_loss.get().data\n",
    "\n",
    "    # Train Alice's Model\n",
    "    DB_opt.zero_grad()\n",
    "    DB_pred = DB_model(d_x_train_ptr)\n",
    "    DB_loss = ((DB_pred - d_y_train_ptr)**2).sum()\n",
    "    DB_loss.backward()\n",
    "\n",
    "    DB_opt.step()\n",
    "    DB_loss = DB_loss.get().data\n",
    "\n",
    "    total_b = n_bm\n",
    "    correct = 0\n",
    "    outputs_b = BM_model(b_x_test_ptr)\n",
    "    _b, pred_b = torch.max(outputs_b.data, 1)\n",
    "    vb, labels_b = torch.max(b_y_test_ptr.data, 1)\n",
    "    correct+= (pred_b == labels_b).sum()\n",
    "    accuracy_b = 100*correct/total_b\n",
    "    print(\"Iteration:\", i, \"BM Accuracy: \", accuracy_b.get().data)\n",
    "\n",
    "    total_d = n_db\n",
    "    correct = 0\n",
    "    outputs_d = DB_model(d_x_test_ptr)\n",
    "    _d, pred_d = torch.max(outputs_d.data, 1)\n",
    "    vd, labels_d = torch.max(d_y_test_ptr.data, 1)\n",
    "    correct+= (pred_d == labels_d).sum()\n",
    "    accuracy_d = 100*correct/total_d\n",
    "    print(\"Iteration:\", i, \"DB Accuracy: \", accuracy_d.get().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ACM KDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bobs_model = my_model.copy().send(Bob)\n",
    "alices_model = my_model.copy().send(Alice)\n",
    "\n",
    "bobs_opt = torch.optim.SGD(params=bobs_model.parameters(),lr=lr_rate)\n",
    "alices_opt = torch.optim.SGD(params=alices_model.parameters(),lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Bob._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "\n",
    "    # Train Bob's Model\n",
    "    bobs_opt.zero_grad()\n",
    "    bobs_pred = bobs_model(b_x_train_ptr)\n",
    "    bobs_loss = ((bobs_pred - b_y_train_ptr)**2).sum()\n",
    "    bobs_loss.backward()\n",
    "\n",
    "    bobs_opt.step()\n",
    "    bobs_loss = bobs_loss.get().data\n",
    "\n",
    "    # Train Alice's Model\n",
    "    alices_opt.zero_grad()\n",
    "    alices_pred = alices_model(a_x_train_ptr)\n",
    "    alices_loss = ((alices_pred - a_y_train_ptr)**2).sum()\n",
    "    alices_loss.backward()\n",
    "\n",
    "    alices_opt.step()\n",
    "    alices_loss = alices_loss.get().data\n",
    "\n",
    "    total = 24701\n",
    "    correct = 0\n",
    "    outputs_a = alices_model(a_x_test_ptr)\n",
    "    _a, pred_a = torch.max(outputs_a.data, 1)\n",
    "    va, labels_a = torch.max(a_y_test_ptr.data, 1)\n",
    "    correct+= (pred_a == labels_a).sum()\n",
    "    accuracy_a = 100*correct/total\n",
    "    print(\"Iteration:\", i, \"ALice Accuracy: \", accuracy_a.get().data)\n",
    "\n",
    "    correct = 0\n",
    "    outputs_b = bobs_model(b_x_test_ptr)\n",
    "    _b, pred_b = torch.max(outputs_b.data, 1)\n",
    "    vb, labels_b = torch.max(b_y_test_ptr.data, 1)\n",
    "    correct+= (pred_b == labels_b).sum()\n",
    "    accuracy_b = 100*correct/total\n",
    "    print(\"Iteration:\", i, \"Bob Accuracy: \", accuracy_b.get().data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Bob._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Alice._objects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pysyft] *",
   "language": "python",
   "name": "conda-env-Pysyft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
