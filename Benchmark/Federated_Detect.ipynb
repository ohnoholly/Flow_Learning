{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Pysyft/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/Pysyft/lib/python3.6/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import Sklearn_PyTorch\n",
    "\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACM KDD'99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (494020, 42)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../../Dataset/KDD99/kddcup99.csv\"\n",
    "\n",
    "dataset = pd.read_csv(data_path, sep=',', usecols=range(0, 42))\n",
    "\n",
    "print(\"Dataset Shape:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_server = dataset.sample(frac=0.5, random_state=1)\n",
    "dataset = dataset.drop(data_server.index)\n",
    "data_alice = dataset.sample(frac=0.5, random_state=1)\n",
    "data_bob = dataset.drop(data_alice.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        duration protocol_type  service flag  src_bytes  dst_bytes  land  \\\n",
      "175542         0          icmp    ecr_i   SF       1032          0     0   \n",
      "399593         0          icmp    ecr_i   SF        520          0     0   \n",
      "378282         0           tcp  private   S0          0          0     0   \n",
      "338019         0          icmp    ecr_i   SF       1032          0     0   \n",
      "174680         0          icmp    ecr_i   SF       1032          0     0   \n",
      "...          ...           ...      ...  ...        ...        ...   ...   \n",
      "322889         0          icmp    ecr_i   SF       1032          0     0   \n",
      "213783         0          icmp    ecr_i   SF       1032          0     0   \n",
      "259270         0          icmp    ecr_i   SF       1032          0     0   \n",
      "458893         0           tcp     http   SF        312        380     0   \n",
      "37308          0           tcp     http   SF        318        438     0   \n",
      "\n",
      "        wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
      "175542               0       0    0  ...                 255   \n",
      "399593               0       0    0  ...                 255   \n",
      "378282               0       0    0  ...                  13   \n",
      "338019               0       0    0  ...                 255   \n",
      "174680               0       0    0  ...                 255   \n",
      "...                ...     ...  ...  ...                 ...   \n",
      "322889               0       0    0  ...                 255   \n",
      "213783               0       0    0  ...                 255   \n",
      "259270               0       0    0  ...                 255   \n",
      "458893               0       0    0  ...                 255   \n",
      "37308                0       0    0  ...                 255   \n",
      "\n",
      "        dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "175542                    1.00                    0.00   \n",
      "399593                    1.00                    0.00   \n",
      "378282                    0.05                    0.05   \n",
      "338019                    1.00                    0.00   \n",
      "174680                    1.00                    0.00   \n",
      "...                        ...                     ...   \n",
      "322889                    1.00                    0.00   \n",
      "213783                    1.00                    0.00   \n",
      "259270                    1.00                    0.00   \n",
      "458893                    1.00                    0.00   \n",
      "37308                     1.00                    0.00   \n",
      "\n",
      "        dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "175542                          1.0                          0.0   \n",
      "399593                          1.0                          0.0   \n",
      "378282                          0.0                          0.0   \n",
      "338019                          1.0                          0.0   \n",
      "174680                          1.0                          0.0   \n",
      "...                             ...                          ...   \n",
      "322889                          1.0                          0.0   \n",
      "213783                          1.0                          0.0   \n",
      "259270                          1.0                          0.0   \n",
      "458893                          0.0                          0.0   \n",
      "37308                           0.0                          0.0   \n",
      "\n",
      "        dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "175542                   0.0                       0.0                   0.0   \n",
      "399593                   0.0                       0.0                   0.0   \n",
      "378282                   1.0                       1.0                   0.0   \n",
      "338019                   0.0                       0.0                   0.0   \n",
      "174680                   0.0                       0.0                   0.0   \n",
      "...                      ...                       ...                   ...   \n",
      "322889                   0.0                       0.0                   0.0   \n",
      "213783                   0.0                       0.0                   0.0   \n",
      "259270                   0.0                       0.0                   0.0   \n",
      "458893                   0.0                       0.0                   0.0   \n",
      "37308                    0.0                       0.0                   0.0   \n",
      "\n",
      "        dst_host_srv_rerror_rate    label  \n",
      "175542                       0.0    smurf  \n",
      "399593                       0.0    smurf  \n",
      "378282                       0.0  neptune  \n",
      "338019                       0.0    smurf  \n",
      "174680                       0.0    smurf  \n",
      "...                          ...      ...  \n",
      "322889                       0.0    smurf  \n",
      "213783                       0.0    smurf  \n",
      "259270                       0.0    smurf  \n",
      "458893                       0.0   normal  \n",
      "37308                        0.0   normal  \n",
      "\n",
      "[247010 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming categorical feature to numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoding(data):\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == type(object):\n",
    "            le_x = preprocessing.LabelEncoder()\n",
    "            le_x.fit(data[col])\n",
    "            data[col] = le_x.transform(data[col])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_server_x = pd.DataFrame(data_server.iloc[:, 0:41])\n",
    "data_server_y = pd.DataFrame(data_server.iloc[:, 41])\n",
    "data_alice_x = pd.DataFrame(data_alice.iloc[:, 0:41])\n",
    "data_alice_y = pd.DataFrame(data_alice.iloc[:, 41])\n",
    "data_bob_x = pd.DataFrame(data_bob.iloc[:, 0:41])\n",
    "data_bob_y = pd.DataFrame(data_bob.iloc[:, 41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_class = {'back':'abnormal', 'buffer_overflow':'abnormal', 'ftp_write':'abnormal', 'guess_passwd':'abnormal', 'imap':'abnormal',\n",
    "            'ipsweep':'abnormal', 'land':'abnormal', 'loadmodule':'abnormal', 'multihop':'abnormal', 'neptune':'abnormal', 'nmap':'abnormal',\n",
    "            'perl':'abnormal', 'phf':'abnormal', 'pod':'abnormal', 'portsweep':'abnormal', 'rootkit':'abnormal', 'satan':'abnormal',\n",
    "            'smurf':'abnormal', 'spy':'abnormal', 'teardrop':'abnormal', 'warezclient':'abnormal', 'warezmaster':'abnormal'}\n",
    "data_server_y = data_server_y.replace(new_class)\n",
    "data_alice_y = data_alice_y.replace(new_class)\n",
    "data_bob_y = data_bob_y.replace(new_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_server_x = encoding(data_server_x)\n",
    "data_server_y = encoding(data_server_y)\n",
    "data_alice_x = encoding(data_alice_x)\n",
    "data_alice_y = encoding(data_alice_y)\n",
    "data_bob_x = encoding(data_bob_x)\n",
    "data_bob_y = encoding(data_bob_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
      "175542         0              0       14     9       1032          0     0   \n",
      "399593         0              0       14     9        520          0     0   \n",
      "378282         0              1       44     5          0          0     0   \n",
      "338019         0              0       14     9       1032          0     0   \n",
      "174680         0              0       14     9       1032          0     0   \n",
      "...          ...            ...      ...   ...        ...        ...   ...   \n",
      "322889         0              0       14     9       1032          0     0   \n",
      "213783         0              0       14     9       1032          0     0   \n",
      "259270         0              0       14     9       1032          0     0   \n",
      "458893         0              1       22     9        312        380     0   \n",
      "37308          0              1       22     9        318        438     0   \n",
      "\n",
      "        wrong_fragment  urgent  hot  ...  dst_host_count  dst_host_srv_count  \\\n",
      "175542               0       0    0  ...             255                 255   \n",
      "399593               0       0    0  ...             255                 255   \n",
      "378282               0       0    0  ...             255                  13   \n",
      "338019               0       0    0  ...             255                 255   \n",
      "174680               0       0    0  ...             255                 255   \n",
      "...                ...     ...  ...  ...             ...                 ...   \n",
      "322889               0       0    0  ...             255                 255   \n",
      "213783               0       0    0  ...             255                 255   \n",
      "259270               0       0    0  ...             255                 255   \n",
      "458893               0       0    0  ...             255                 255   \n",
      "37308                0       0    0  ...             255                 255   \n",
      "\n",
      "        dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "175542                    1.00                    0.00   \n",
      "399593                    1.00                    0.00   \n",
      "378282                    0.05                    0.05   \n",
      "338019                    1.00                    0.00   \n",
      "174680                    1.00                    0.00   \n",
      "...                        ...                     ...   \n",
      "322889                    1.00                    0.00   \n",
      "213783                    1.00                    0.00   \n",
      "259270                    1.00                    0.00   \n",
      "458893                    1.00                    0.00   \n",
      "37308                     1.00                    0.00   \n",
      "\n",
      "        dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "175542                          1.0                          0.0   \n",
      "399593                          1.0                          0.0   \n",
      "378282                          0.0                          0.0   \n",
      "338019                          1.0                          0.0   \n",
      "174680                          1.0                          0.0   \n",
      "...                             ...                          ...   \n",
      "322889                          1.0                          0.0   \n",
      "213783                          1.0                          0.0   \n",
      "259270                          1.0                          0.0   \n",
      "458893                          0.0                          0.0   \n",
      "37308                           0.0                          0.0   \n",
      "\n",
      "        dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "175542                   0.0                       0.0                   0.0   \n",
      "399593                   0.0                       0.0                   0.0   \n",
      "378282                   1.0                       1.0                   0.0   \n",
      "338019                   0.0                       0.0                   0.0   \n",
      "174680                   0.0                       0.0                   0.0   \n",
      "...                      ...                       ...                   ...   \n",
      "322889                   0.0                       0.0                   0.0   \n",
      "213783                   0.0                       0.0                   0.0   \n",
      "259270                   0.0                       0.0                   0.0   \n",
      "458893                   0.0                       0.0                   0.0   \n",
      "37308                    0.0                       0.0                   0.0   \n",
      "\n",
      "        dst_host_srv_rerror_rate  \n",
      "175542                       0.0  \n",
      "399593                       0.0  \n",
      "378282                       0.0  \n",
      "338019                       0.0  \n",
      "174680                       0.0  \n",
      "...                          ...  \n",
      "322889                       0.0  \n",
      "213783                       0.0  \n",
      "259270                       0.0  \n",
      "458893                       0.0  \n",
      "37308                        0.0  \n",
      "\n",
      "[247010 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_server_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(df): \n",
    "    x = df.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df = pd.DataFrame(x_scaled)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_server_x = normalize(data_server_x)\n",
    "data_alice_x = normalize(data_alice_x)\n",
    "data_bob_x = normalize(data_bob_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0    1         2    3             4         5    6    7    8    9   \\\n",
      "0       0.0  0.0  0.222222  0.9  1.488371e-06  0.000000  0.0  0.0  0.0  0.0   \n",
      "1       0.0  0.0  0.222222  0.9  7.499542e-07  0.000000  0.0  0.0  0.0  0.0   \n",
      "2       0.0  0.5  0.698413  0.5  0.000000e+00  0.000000  0.0  0.0  0.0  0.0   \n",
      "3       0.0  0.0  0.222222  0.9  1.488371e-06  0.000000  0.0  0.0  0.0  0.0   \n",
      "4       0.0  0.0  0.222222  0.9  1.488371e-06  0.000000  0.0  0.0  0.0  0.0   \n",
      "...     ...  ...       ...  ...           ...       ...  ...  ...  ...  ...   \n",
      "247005  0.0  0.0  0.222222  0.9  1.488371e-06  0.000000  0.0  0.0  0.0  0.0   \n",
      "247006  0.0  0.0  0.222222  0.9  1.488371e-06  0.000000  0.0  0.0  0.0  0.0   \n",
      "247007  0.0  0.0  0.222222  0.9  1.488371e-06  0.000000  0.0  0.0  0.0  0.0   \n",
      "247008  0.0  0.5  0.349206  0.9  4.499725e-07  0.000074  0.0  0.0  0.0  0.0   \n",
      "247009  0.0  0.5  0.349206  0.9  4.586259e-07  0.000085  0.0  0.0  0.0  0.0   \n",
      "\n",
      "        ...   31        32    33    34   35   36   37   38   39   40  \n",
      "0       ...  1.0  1.000000  1.00  0.00  1.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1       ...  1.0  1.000000  1.00  0.00  1.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2       ...  1.0  0.047244  0.05  0.05  0.0  0.0  1.0  1.0  0.0  0.0  \n",
      "3       ...  1.0  1.000000  1.00  0.00  1.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4       ...  1.0  1.000000  1.00  0.00  1.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...     ...  ...       ...   ...   ...  ...  ...  ...  ...  ...  ...  \n",
      "247005  ...  1.0  1.000000  1.00  0.00  1.0  0.0  0.0  0.0  0.0  0.0  \n",
      "247006  ...  1.0  1.000000  1.00  0.00  1.0  0.0  0.0  0.0  0.0  0.0  \n",
      "247007  ...  1.0  1.000000  1.00  0.00  1.0  0.0  0.0  0.0  0.0  0.0  \n",
      "247008  ...  1.0  1.000000  1.00  0.00  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "247009  ...  1.0  1.000000  1.00  0.00  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[247010 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_server_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(data_server_y)\n",
    "data_server_y = enc.transform(data_server_y).toarray() #Encode the classes to a binary array \n",
    "enc.fit(data_alice_y)\n",
    "data_alice_y = enc.transform(data_alice_y).toarray()\n",
    "enc.fit(data_bob_y)\n",
    "data_bob_y = enc.transform(data_bob_y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247010, 2)\n",
      "(123505, 2)\n",
      "(123505, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data_server_y.shape)\n",
    "print(data_alice_y.shape)\n",
    "print(data_bob_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(data_server_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IoT Botnet Stream Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all the data from the CSV file \n",
    "BM_DATA_PATH = \"../../../Dataset/Botnet_Detection/Philips_B120N10_Baby_Monitor\"\n",
    "DB_DATA_PATH = \"../../../Dataset/Botnet_Detection/Danmini_Doorbell\"\n",
    "ET_DATA_PATH = \"../../../Dataset/Botnet_Detection/Ecobee_Thermostat\"\n",
    "df_bm_b = pd.read_csv(BM_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_bm_m = pd.read_csv(BM_DATA_PATH+\"/Mirai/udp.csv\")\n",
    "df_db_b = pd.read_csv(DB_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_db_m = pd.read_csv(DB_DATA_PATH+\"/Mirai/udp.csv\")\n",
    "df_et_b = pd.read_csv(ET_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_et_m = pd.read_csv(ET_DATA_PATH+\"/Mirai/udp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df_bm_g.shape)\n",
    "print(df_db_g.shape)\n",
    "print(df_et_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list(data) or \n",
    "list(df_bm_b.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bm_b.iloc[:, 13:16].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Transfering data to workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Alice = sy.VirtualWorker(hook, id='Alice')\n",
    "Bob = sy.VirtualWorker(hook, id='Bob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "a_train_x, a_test_x, a_train_y, a_test_y = train_test_split(data_alice_x, data_alice_y, test_size=0.20)\n",
    "b_train_x, b_test_x, b_train_y, b_test_y = train_test_split(data_bob_x, data_bob_y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_server_x = torch.FloatTensor(data_server_x.values.astype(np.float32))\n",
    "tensor_server_y = torch.FloatTensor(data_server_y.astype(np.float32))\n",
    "t_a_train_x = torch.tensor(a_train_x.values.astype(np.float32))\n",
    "t_a_test_x = torch.tensor(a_test_x.values.astype(np.float32))\n",
    "t_a_train_y = torch.tensor(a_train_y.astype(np.float32))\n",
    "t_a_test_y = torch.tensor(a_test_y.astype(np.float32))\n",
    "t_b_train_x = torch.tensor(b_train_x.values.astype(np.float32))\n",
    "t_b_test_x = torch.tensor(b_test_x.values.astype(np.float32))\n",
    "t_b_train_y = torch.tensor(b_train_y.astype(np.float32))\n",
    "t_b_test_y = torch.tensor(b_test_y.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24701, 2])\n",
      "torch.Size([24701, 2])\n"
     ]
    }
   ],
   "source": [
    "print(t_b_test_y.shape)\n",
    "print(t_a_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_x_train_ptr = t_a_train_x.send(Alice)\n",
    "a_x_test_ptr = t_a_test_x.send(Alice)\n",
    "a_y_train_ptr = t_a_train_y.send(Alice)\n",
    "a_y_test_ptr = t_a_test_y.send(Alice)\n",
    "b_x_train_ptr = t_b_train_x.send(Bob)\n",
    "b_x_test_ptr = t_b_test_x.send(Bob)\n",
    "b_y_train_ptr = t_b_train_y.send(Bob)\n",
    "b_y_test_ptr = t_b_test_y.send(Bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10342095302: tensor([[0.0000, 0.0000, 0.2188,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.3438,  ..., 0.0100, 0.0400, 0.0400],\n",
      "        [0.0000, 0.0000, 0.2188,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.2188,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2188,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.7031,  ..., 1.0000, 0.0000, 0.0000]]), 69127704134: tensor([[0.0000, 0.0000, 0.2188,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2188,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.7031,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.5000, 0.7031,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.7031,  ..., 0.0000, 1.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.2188,  ..., 0.0000, 0.0000, 0.0000]]), 8457591110: tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]), 47100924285: tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])}\n"
     ]
    }
   ],
   "source": [
    "print(Bob._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{64943329861: tensor([[0.0000, 0.5000, 0.3548,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.7097,  ..., 0.0000, 1.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.2258,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 1.0000, 0.1774,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.7097,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.7097,  ..., 0.0000, 1.0000, 1.0000]]), 66078015922: tensor([[0.0000, 0.5000, 0.7097,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.7097,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2258,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.5000, 0.7097,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.3548,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2258,  ..., 0.0000, 0.0000, 0.0000]]), 31634114022: tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]]), 93807833313: tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])}\n"
     ]
    }
   ],
   "source": [
    "print(Alice._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.2222,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2222,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.6984,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.2222,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.3492,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.3492,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_server_x)\n",
    "print(tensor_server_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ec3340b9268b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Fitting function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_server_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_server_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/Sklearn_PyTorch-0.1.0-py3.6.egg/Sklearn_PyTorch/random_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, vectors, labels)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0msampled_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0msampled_featured_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_featured_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0msampled_featured_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/Sklearn_PyTorch-0.1.0-py3.6.egg/Sklearn_PyTorch/binary_tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, vectors, labels, criterion)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/Sklearn_PyTorch-0.1.0-py3.6.egg/Sklearn_PyTorch/binary_tree.py\u001b[0m in \u001b[0;36m_build_tree\u001b[0;34m(self, vectors, labels, func, depth)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mDecisionNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mcurrent_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mbest_gain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mbest_criteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/Sklearn_PyTorch-0.1.0-py3.6.egg/Sklearn_PyTorch/utils.py\u001b[0m in \u001b[0;36mentropy\u001b[0;34m(labels)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mEntropy\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \"\"\"\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0ment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/Sklearn_PyTorch-0.1.0-py3.6.egg/Sklearn_PyTorch/utils.py\u001b[0m in \u001b[0;36munique_counts\u001b[0;34m(labels)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mroute_method_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# means that there is a wrapper to remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Pysyft/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "from Sklearn_PyTorch import TorchRandomForestClassifier\n",
    "\n",
    "# Initialisation of the model\n",
    "my_model = TorchRandomForestClassifier(nb_trees=100, nb_samples=3, max_depth=5, bootstrap=True)\n",
    "\n",
    "# Fitting function\n",
    "my_model.fit(tensor_server_x, tensor_server_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "input_dim = 41\n",
    "output_dim = 2 #Number of clasees\n",
    "lr_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_dim, output_dim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(epochs, model, data, labels):\n",
    "    print(epochs)\n",
    "    for epochs in range(int(epochs)):    \n",
    "        print(\"In the loop\")\n",
    "        optimizer.zero_grad() ## Zero out the gradient\n",
    "        outputs = model(data) ## Call forward\n",
    "        print(outputs)\n",
    "        print(labels)\n",
    "        loss = ((outputs - labels)**2).sum() ## softmax\n",
    "        print(loss)\n",
    "        loss.backward() ## Accumulated gradient updates into x\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_server_y = tensor_server_y.squeeze()\n",
    "training(epochs, model, tensor_server_x, tensor_server_y) ## Train the initial model on Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer model to clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bobs_model = model.copy().send(Bob)\n",
    "alices_model = model.copy().send(Alice)\n",
    "\n",
    "bobs_opt = torch.optim.SGD(params=bobs_model.parameters(),lr=lr_rate)\n",
    "alices_opt = torch.optim.SGD(params=alices_model.parameters(),lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Bob._objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sencond Training with local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "\n",
    "    # Train Bob's Model\n",
    "    bobs_opt.zero_grad()\n",
    "    bobs_pred = bobs_model(b_x_train_ptr)\n",
    "    bobs_loss = ((bobs_pred - b_y_train_ptr)**2).sum()\n",
    "    bobs_loss.backward()\n",
    "\n",
    "    bobs_opt.step()\n",
    "    bobs_loss = bobs_loss.get().data\n",
    "\n",
    "    # Train Alice's Model\n",
    "    alices_opt.zero_grad()\n",
    "    alices_pred = alices_model(a_x_train_ptr)\n",
    "    alices_loss = ((alices_pred - a_y_train_ptr)**2).sum()\n",
    "    alices_loss.backward()\n",
    "\n",
    "    alices_opt.step()\n",
    "    alices_loss = alices_loss.get().data\n",
    "\n",
    "    total = 24701\n",
    "    correct = 0\n",
    "    outputs_a = alices_model(a_x_test_ptr)\n",
    "    _a, pred_a = torch.max(outputs_a.data, 1)\n",
    "    va, labels_a = torch.max(a_y_test_ptr.data, 1)\n",
    "    correct+= (pred_a == labels_a).sum()\n",
    "    accuracy_a = 100*correct/total\n",
    "    print(\"Iteration:\", i, \"ALice Accuracy: \", accuracy_a.get().data)\n",
    "\n",
    "    correct = 0\n",
    "    outputs_b = bobs_model(b_x_test_ptr)\n",
    "    _b, pred_b = torch.max(outputs_b.data, 1)\n",
    "    vb, labels_b = torch.max(b_y_test_ptr.data, 1)\n",
    "    correct+= (pred_b == labels_b).sum()\n",
    "    accuracy_b = 100*correct/total\n",
    "    print(\"Iteration:\", i, \"Bob Accuracy: \", accuracy_b.get().data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Bob._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Alice._objects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pysyft] *",
   "language": "python",
   "name": "conda-env-Pysyft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
