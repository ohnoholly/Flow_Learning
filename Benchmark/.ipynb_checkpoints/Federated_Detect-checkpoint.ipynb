{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Pysyft/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/Pysyft/lib/python3.6/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import Sklearn_PyTorch\n",
    "\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(df): \n",
    "    x = df.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df = pd.DataFrame(x_scaled)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming categorical feature to numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoding(data):\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == type(object):\n",
    "            le_x = preprocessing.LabelEncoder()\n",
    "            le_x.fit(data[col])\n",
    "            data[col] = le_x.transform(data[col])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def label_encoder(df):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(df)\n",
    "    print(enc.categories_)\n",
    "    df_array = enc.transform(df).toarray() #Encode the classes to a binary array \n",
    "    return df_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACM KDD'99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../../Dataset/KDD99/kddcup99.csv\"\n",
    "\n",
    "dataset = pd.read_csv(data_path, sep=',', usecols=range(0, 42))\n",
    "\n",
    "print(\"Dataset Shape:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Randomly split data into three parts\n",
    "data_server = dataset.sample(frac=0.5, random_state=1)\n",
    "dataset = dataset.drop(data_server.index)\n",
    "data_alice = dataset.sample(frac=0.5, random_state=1)\n",
    "data_bob = dataset.drop(data_alice.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Divide data into x and y\n",
    "data_server_x = pd.DataFrame(data_server.iloc[:, 0:41])\n",
    "data_server_y = pd.DataFrame(data_server.iloc[:, 41])\n",
    "data_alice_x = pd.DataFrame(data_alice.iloc[:, 0:41])\n",
    "data_alice_y = pd.DataFrame(data_alice.iloc[:, 41])\n",
    "data_bob_x = pd.DataFrame(data_bob.iloc[:, 0:41])\n",
    "data_bob_y = pd.DataFrame(data_bob.iloc[:, 41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Relabel data into biclasses\n",
    "new_class = {'back':'abnormal', 'buffer_overflow':'abnormal', 'ftp_write':'abnormal', 'guess_passwd':'abnormal', 'imap':'abnormal',\n",
    "            'ipsweep':'abnormal', 'land':'abnormal', 'loadmodule':'abnormal', 'multihop':'abnormal', 'neptune':'abnormal', 'nmap':'abnormal',\n",
    "            'perl':'abnormal', 'phf':'abnormal', 'pod':'abnormal', 'portsweep':'abnormal', 'rootkit':'abnormal', 'satan':'abnormal',\n",
    "            'smurf':'abnormal', 'spy':'abnormal', 'teardrop':'abnormal', 'warezclient':'abnormal', 'warezmaster':'abnormal'}\n",
    "data_server_y = data_server_y.replace(new_class)\n",
    "data_alice_y = data_alice_y.replace(new_class)\n",
    "data_bob_y = data_bob_y.replace(new_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode the string datatype to numerial\n",
    "data_server_x = encoding(data_server_x)\n",
    "data_server_y = encoding(data_server_y)\n",
    "data_alice_x = encoding(data_alice_x)\n",
    "data_alice_y = encoding(data_alice_y)\n",
    "data_bob_x = encoding(data_bob_x)\n",
    "data_bob_y = encoding(data_bob_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize x data\n",
    "data_server_x = normalize(data_server_x)\n",
    "data_alice_x = normalize(data_alice_x)\n",
    "data_bob_x = normalize(data_bob_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One-Hot encoding labels\n",
    "data_server_y = label_encoder(data_server_y)\n",
    "data_alice_y = label_encoder(data_alice_y)\n",
    "data_bob_y = label_encoder(data_bob_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_server_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IoT Botnet Stream Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the data from the CSV file \n",
    "BM_DATA_PATH = \"../../../Dataset/Botnet_Detection/Philips_B120N10_Baby_Monitor\"\n",
    "DB_DATA_PATH = \"../../../Dataset/Botnet_Detection/Danmini_Doorbell\"\n",
    "ET_DATA_PATH = \"../../../Dataset/Botnet_Detection/Ecobee_Thermostat\"\n",
    "PT_DATA_PATH = \"../../../Dataset/Botnet_Detection/PT_838_Security Camera\"\n",
    "XC_DATA_PATH = \"../../../Dataset/Botnet_Detection/XCS7_1002_WHT_Security_Camera\"\n",
    "df_bm_b = pd.read_csv(BM_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_bm_m = pd.read_csv(BM_DATA_PATH+\"/Mirai/udp.csv\")\n",
    "df_db_b = pd.read_csv(DB_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_db_m = pd.read_csv(DB_DATA_PATH+\"/Mirai/udp.csv\")\n",
    "df_et_b = pd.read_csv(ET_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_et_m = pd.read_csv(ET_DATA_PATH+\"/Mirai/udp.csv\")\n",
    "df_pt_b = pd.read_csv(ET_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_pt_m = pd.read_csv(ET_DATA_PATH+\"/Mirai/udp.csv\")\n",
    "df_xc_b = pd.read_csv(XC_DATA_PATH+\"/benign_traffic.csv\")\n",
    "df_xc_m = pd.read_csv(XC_DATA_PATH+\"/Mirai/udp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assign the label to each dataframe\n",
    "df_bm_b = df_bm_b.assign(label = 'b') \n",
    "df_db_b = df_db_b.assign(label = 'b') \n",
    "df_et_b = df_et_b.assign(label = 'b')\n",
    "df_pt_b = df_pt_b.assign(label = 'b')\n",
    "df_xc_b = df_xc_b.assign(label = 'b')\n",
    "df_bm_m = df_bm_m.assign(label = 'm')\n",
    "df_db_m = df_db_m.assign(label = 'm') \n",
    "df_et_m = df_et_m.assign(label = 'm') \n",
    "df_pt_m = df_pt_m.assign(label = 'm')\n",
    "df_xc_m = df_xc_m.assign(label = 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151481, 116)\n",
      "(13113, 116)\n",
      "(151879, 116)\n",
      "(46585, 116)\n"
     ]
    }
   ],
   "source": [
    "print(df_pt_m.shape)\n",
    "print(df_pt_b.shape)\n",
    "print(df_xc_m.shape)\n",
    "print(df_xc_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the benign traffic and malicious traffic\n",
    "df_bm = df_bm_b\n",
    "df_bm = df_bm.append(df_bm_m, ignore_index = True)\n",
    "df_db = df_db_b\n",
    "df_db = df_db.append(df_db_m, ignore_index = True)\n",
    "df_et = df_et_b\n",
    "df_et = df_et.append(df_et_m, ignore_index = True)\n",
    "df_pt = df_pt_b\n",
    "df_pt = df_pt.append(df_pt_m, ignore_index = True)\n",
    "df_xc = df_xc_b\n",
    "df_xc = df_xc.append(df_xc_m, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffler(df):\n",
    "  return df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the rows in dataframe\n",
    "df_bm = shuffler(df_bm)\n",
    "df_db = shuffler(df_db)\n",
    "df_et = shuffler(df_et)\n",
    "df_pt = shuffler(df_pt)\n",
    "df_xc = shuffler(df_xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dataset on server for initial model (second version)\n",
    "df_server = pd.DataFrame()\n",
    "df_server = df_server.append(df_et.sample(frac =.25), ignore_index=True)\n",
    "df_server = df_server.append(df_pt.sample(frac =.25), ignore_index=True)\n",
    "df_server = df_server.append(df_xc.sample(frac =.25), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset on server for initial model (first version)\n",
    "df_server = pd.DataFrame()\n",
    "df_server = df_server.append(df_bm.sample(frac =.25), ignore_index=True)\n",
    "df_server = df_server.append(df_db.sample(frac =.25), ignore_index=True)\n",
    "df_server = df_server.append(df_et.sample(frac =.25), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131912, 116)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_server.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide dataframe into x and y\n",
    "df_s_x = pd.DataFrame(df_server.iloc[:, 0:115])\n",
    "df_s_y = pd.DataFrame(df_server.iloc[:, 115])\n",
    "df_bm_x = pd.DataFrame(df_bm.iloc[:, 0:115])\n",
    "df_bm_y = pd.DataFrame(df_bm.iloc[:, 115])\n",
    "df_db_x = pd.DataFrame(df_db.iloc[:, 0:115])\n",
    "df_db_y = pd.DataFrame(df_db.iloc[:, 115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the x dataframe\n",
    "df_s_x = normalize(df_s_x)\n",
    "df_bm_x = normalize(df_bm_x)\n",
    "df_db_x = normalize(df_db_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392274, 116)\n"
     ]
    }
   ],
   "source": [
    "print(df_bm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131912, 115)\n"
     ]
    }
   ],
   "source": [
    "print(df_s_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287213, 115)\n"
     ]
    }
   ],
   "source": [
    "print(df_db_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['b', 'm'], dtype=object)]\n",
      "[array(['b', 'm'], dtype=object)]\n",
      "[array(['b', 'm'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "#One-Hot encoding labels and transform into array\n",
    "s_y = label_encoder(df_s_y)\n",
    "bm_y = label_encoder(df_bm_y)\n",
    "db_y = label_encoder(df_db_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Transfering data to workers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ELM(torch.nn.Module):\n",
    "    def __init__(self, n_inputs: int, hidden_units = 1000):\n",
    "        self.random_weights = np.random.normal(size=[n_inputs, hidden_units]) # A random weight is assigned\n",
    "    \n",
    "    def learn(self, X: np.ndarray, Y: np.ndarray):\n",
    "        H = self._hidden_layer(X)\n",
    "        self.output_weights = np.linalg.pinv(H) @ Y\n",
    "    \n",
    "    def _f(self, x: np.ndarray): \n",
    "        return 1. / (1. + np.exp(-x)) #activation function: sigmoid\n",
    "    \n",
    "    def _hidden_layer(self, inputs: np.ndarray): \n",
    "        return self._f(inputs @ self.random_weights)\n",
    "  \n",
    "    def _output_layer(self, hidden: np.ndarray): \n",
    "        return hidden @ self.output_weights\n",
    "  \n",
    "    def __call__(self, inputs: np.ndarray):  #infer\n",
    "        return self._output_layer(self._hidden_layer(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IoT BotNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BM = sy.VirtualWorker(hook, id='BM')\n",
    "DB = sy.VirtualWorker(hook, id='DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "b_train_x, b_test_x, b_train_y, b_test_y = train_test_split(df_bm_x, bm_y, test_size=0.20)\n",
    "d_train_x, d_test_x, d_train_y, d_test_y = train_test_split(df_db_x, db_y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_server_x = torch.FloatTensor(df_s_x.values.astype(np.float32))\n",
    "tensor_server_y = torch.FloatTensor(s_y.astype(np.float32))\n",
    "t_b_train_x = torch.FloatTensor(b_train_x.values.astype(np.float32))\n",
    "t_b_test_x = torch.tensor(b_test_x.values.astype(np.float32))\n",
    "t_b_train_y = torch.tensor(b_train_y.astype(np.float32))\n",
    "t_b_test_y = torch.tensor(b_test_y.astype(np.float32))\n",
    "t_d_train_x = torch.tensor(d_train_x.values.astype(np.float32))\n",
    "t_d_test_x = torch.tensor(d_test_x.values.astype(np.float32))\n",
    "t_d_train_y = torch.tensor(d_train_y.astype(np.float32))\n",
    "t_d_test_y = torch.tensor(d_test_y.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([229770, 115])\n",
      "torch.Size([57443, 115])\n"
     ]
    }
   ],
   "source": [
    "print(t_d_train_x.shape)\n",
    "print(t_d_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_x_train_ptr = t_b_train_x.send(BM)\n",
    "b_x_test_ptr = t_b_test_x.send(BM)\n",
    "b_y_train_ptr = t_b_train_y.send(BM)\n",
    "b_y_test_ptr = t_b_test_y.send(BM)\n",
    "d_x_train_ptr = t_d_train_x.send(DB)\n",
    "d_x_test_ptr = t_d_test_x.send(DB)\n",
    "d_y_train_ptr = t_d_train_y.send(DB)\n",
    "d_y_test_ptr = t_d_test_y.send(DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ACM KDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Alice = sy.VirtualWorker(hook, id='Alice')\n",
    "Bob = sy.VirtualWorker(hook, id='Bob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "a_train_x, a_test_x, a_train_y, a_test_y = train_test_split(data_alice_x, data_alice_y, test_size=0.20)\n",
    "b_train_x, b_test_x, b_train_y, b_test_y = train_test_split(data_bob_x, data_bob_y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_server_x = torch.FloatTensor(data_server_x.values.astype(np.float32))\n",
    "tensor_server_y = torch.FloatTensor(data_server_y.values.astype(np.float32))\n",
    "t_a_train_x = torch.tensor(a_train_x.values.astype(np.float32))\n",
    "t_a_test_x = torch.tensor(a_test_x.values.astype(np.float32))\n",
    "t_a_train_y = torch.tensor(a_train_y.values.astype(np.float32))\n",
    "t_a_test_y = torch.tensor(a_test_y.values.astype(np.float32))\n",
    "t_b_train_x = torch.FloatTensor(b_train_x.values.astype(np.float32))\n",
    "t_b_test_x = torch.tensor(b_test_x.values.astype(np.float32))\n",
    "t_b_train_y = torch.tensor(b_train_y.values.astype(np.float32))\n",
    "t_b_test_y = torch.tensor(b_test_y.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_b_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_x_train_ptr = t_a_train_x.send(Alice)\n",
    "a_x_test_ptr = t_a_test_x.send(Alice)\n",
    "a_y_train_ptr = t_a_train_y.send(Alice)\n",
    "a_y_test_ptr = t_a_test_y.send(Alice)\n",
    "b_x_train_ptr = t_b_train_x.send(Bob)\n",
    "b_x_test_ptr = t_b_test_x.send(Bob)\n",
    "b_y_train_ptr = t_b_train_y.send(Bob)\n",
    "b_y_test_ptr = t_b_test_y.send(Bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Bob._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Alice._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensor_server_x)\n",
    "print(tensor_server_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sklearn_PyTorch import TorchRandomForestClassifier\n",
    "\n",
    "# Initialisation of the model\n",
    "my_model = TorchRandomForestClassifier(nb_trees=100, nb_samples=3, max_depth=5, bootstrap=True)\n",
    "\n",
    "# Fitting function\n",
    "my_model.fit(tensor_server_x, tensor_server_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "input_dim = 115\n",
    "output_dim = 2 #Number of clasees\n",
    "lr_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_server_x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ELM(tensor_server_x.size(0), n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training():\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_dim, output_dim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(epochs, model, data, labels):\n",
    "    print(epochs)\n",
    "    for epochs in range(int(epochs)):    \n",
    "        print(\"In the loop\")\n",
    "        optimizer.zero_grad() ## Zero out the gradient\n",
    "        outputs = model(data) ## Call forward\n",
    "        print(outputs)\n",
    "        print(labels)\n",
    "        loss = ((outputs - labels)**2).sum() ## softmax\n",
    "        print(loss)\n",
    "        loss.backward() ## Accumulated gradient updates into x\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([131912, 2])\n",
      "3\n",
      "In the loop\n",
      "tensor([[-0.0124,  0.3223],\n",
      "        [-0.2458,  0.3140],\n",
      "        [-0.0091,  0.3751],\n",
      "        ...,\n",
      "        [-0.2767,  0.2999],\n",
      "        [ 0.0223,  0.3692],\n",
      "        [-0.2024,  0.3914]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "tensor(78220.0781, grad_fn=<SumBackward0>)\n",
      "In the loop\n",
      "tensor([[ 654.7180, 1291.6458],\n",
      "        [1291.6085, 3076.9915],\n",
      "        [ 806.3953, 2153.6287],\n",
      "        ...,\n",
      "        [1312.4276, 3134.3572],\n",
      "        [ 780.8770, 2067.3516],\n",
      "        [1193.5680, 2788.5806]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "tensor(1.1475e+12, grad_fn=<SumBackward0>)\n",
      "In the loop\n",
      "tensor([[ -2573060.5000,  -6170566.0000],\n",
      "        [ -5868652.5000, -14119151.0000],\n",
      "        [ -3904625.0000,  -9520482.0000],\n",
      "        ...,\n",
      "        [ -5973299.5000, -14372144.0000],\n",
      "        [ -3755568.5000,  -9155508.0000],\n",
      "        [ -5342381.0000, -12847866.0000]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "tensor(2.3949e+19, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tensor_server_y = tensor_server_y.squeeze()\n",
    "print(tensor_server_y.shape)\n",
    "training(epochs, model, tensor_server_x, tensor_server_y) ## Train the initial model on Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer model to clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IoTBot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BM_model = model.copy().send(BM)\n",
    "DB_model = model.copy().send(DB)\n",
    "\n",
    "BM_opt = torch.optim.SGD(params=BM_model.parameters(),lr=lr_rate)\n",
    "DB_opt = torch.optim.SGD(params=DB_model.parameters(),lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([78455, 2])\n",
      "torch.Size([57443, 2])\n"
     ]
    }
   ],
   "source": [
    "print(t_b_test_y.shape)\n",
    "print(t_d_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 BM Accuracy:  tensor(44)\n",
      "Iteration: 0 DB Accuracy:  tensor(17)\n",
      "Iteration: 1 BM Accuracy:  tensor(55)\n",
      "Iteration: 1 DB Accuracy:  tensor(82)\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "\n",
    "    # Train Bob's Model\n",
    "    BM_opt.zero_grad()\n",
    "    BM_pred = BM_model(b_x_train_ptr)\n",
    "    BM_loss = ((BM_pred - b_y_train_ptr)**2).sum()\n",
    "    BM_loss.backward()\n",
    "\n",
    "    BM_opt.step()\n",
    "    BM_loss = BM_loss.get().data\n",
    "\n",
    "    # Train Alice's Model\n",
    "    DB_opt.zero_grad()\n",
    "    DB_pred = DB_model(d_x_train_ptr)\n",
    "    DB_loss = ((DB_pred - d_y_train_ptr)**2).sum()\n",
    "    DB_loss.backward()\n",
    "\n",
    "    DB_opt.step()\n",
    "    DB_loss = DB_loss.get().data\n",
    "\n",
    "    total_b = 78455\n",
    "    correct = 0\n",
    "    outputs_b = BM_model(b_x_test_ptr)\n",
    "    _b, pred_b = torch.max(outputs_b.data, 1)\n",
    "    vb, labels_b = torch.max(b_y_test_ptr.data, 1)\n",
    "    correct+= (pred_b == labels_b).sum()\n",
    "    accuracy_b = 100*correct/total_b\n",
    "    print(\"Iteration:\", i, \"BM Accuracy: \", accuracy_b.get().data)\n",
    "\n",
    "    total_d = 57443\n",
    "    correct = 0\n",
    "    outputs_d = DB_model(d_x_test_ptr)\n",
    "    _d, pred_d = torch.max(outputs_d.data, 1)\n",
    "    vd, labels_d = torch.max(d_y_test_ptr.data, 1)\n",
    "    correct+= (pred_d == labels_d).sum()\n",
    "    accuracy_d = 100*correct/total_d\n",
    "    print(\"Iteration:\", i, \"DB Accuracy: \", accuracy_d.get().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ACM KDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_model = my_model.copy().send(Bob)\n",
    "alices_model = my_model.copy().send(Alice)\n",
    "\n",
    "bobs_opt = torch.optim.SGD(params=bobs_model.parameters(),lr=lr_rate)\n",
    "alices_opt = torch.optim.SGD(params=alices_model.parameters(),lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Bob._objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sencond Training with local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "\n",
    "    # Train Bob's Model\n",
    "    bobs_opt.zero_grad()\n",
    "    bobs_pred = bobs_model(b_x_train_ptr)\n",
    "    bobs_loss = ((bobs_pred - b_y_train_ptr)**2).sum()\n",
    "    bobs_loss.backward()\n",
    "\n",
    "    bobs_opt.step()\n",
    "    bobs_loss = bobs_loss.get().data\n",
    "\n",
    "    # Train Alice's Model\n",
    "    alices_opt.zero_grad()\n",
    "    alices_pred = alices_model(a_x_train_ptr)\n",
    "    alices_loss = ((alices_pred - a_y_train_ptr)**2).sum()\n",
    "    alices_loss.backward()\n",
    "\n",
    "    alices_opt.step()\n",
    "    alices_loss = alices_loss.get().data\n",
    "\n",
    "    total = 24701\n",
    "    correct = 0\n",
    "    outputs_a = alices_model(a_x_test_ptr)\n",
    "    _a, pred_a = torch.max(outputs_a.data, 1)\n",
    "    va, labels_a = torch.max(a_y_test_ptr.data, 1)\n",
    "    correct+= (pred_a == labels_a).sum()\n",
    "    accuracy_a = 100*correct/total\n",
    "    print(\"Iteration:\", i, \"ALice Accuracy: \", accuracy_a.get().data)\n",
    "\n",
    "    correct = 0\n",
    "    outputs_b = bobs_model(b_x_test_ptr)\n",
    "    _b, pred_b = torch.max(outputs_b.data, 1)\n",
    "    vb, labels_b = torch.max(b_y_test_ptr.data, 1)\n",
    "    correct+= (pred_b == labels_b).sum()\n",
    "    accuracy_b = 100*correct/total\n",
    "    print(\"Iteration:\", i, \"Bob Accuracy: \", accuracy_b.get().data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Bob._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Alice._objects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pysyft] *",
   "language": "python",
   "name": "conda-env-Pysyft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
